{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.7642974853515625e-05\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "#%%timeit -n 1 -r 1 # time cost for 1 run with 1 loop\n",
    "\n",
    "############################################################### Packages\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from scipy.stats import levy_stable  \n",
    "from sklearn.covariance import empirical_covariance\n",
    "import matplotlib.pyplot as plt\n",
    "#import random\n",
    "import math \n",
    "import pandas as pd\n",
    "import scipy.special\n",
    "#from scipy.stats import rankdata\n",
    "import numba\n",
    "import timeit\n",
    "import time\n",
    "import warnings\n",
    "import psutil\n",
    "\n",
    "############################################################### Miscellenous\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "npr.seed(0)\n",
    "\n",
    "############################################################### Section 1: Generating N*n*d real matrix as data sample for different models\n",
    "\n",
    "\n",
    "######## Inductive model exhibing pairwise independence but not triplewise independence\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def inductive_model_iterated_numba(initializing_normal_sample,N,n,d):\n",
    "    X=np.empty((N,n,d))\n",
    "    for k in numba.prange(N):\n",
    "        for i in numba.prange(n):\n",
    "            X[k,i,0] = initializing_normal_sample[k,i,0]\n",
    "            X[k,i,1] = initializing_normal_sample[k,i,1]\n",
    "            for j in numba.prange(2,d):\n",
    "                if X[k,i,j-1]+X[k,i,j-2] > 1:\n",
    "                     X[k,i,j] =X[k,i,j-1]+X[k,i,j-2]-1\n",
    "                else:\n",
    "                    X[k,i,j] =X[k,i,j-1]+X[k,i,j-2]\n",
    "    return X\n",
    "\n",
    "######## d-variate Gumbel distribution. Algorithm by Marshall-Olkin - @numba.njit\n",
    "######## https://cran.r-project.org/web/packages/copula/vignettes/nacopula-pkg.pdf\n",
    "\n",
    "def Stable_distrib_data(N,n,t):\n",
    "    if t == 1:\n",
    "        V=levy_stable.rvs(1, 1, loc=1, scale=np.cos(math.pi/(2)), size=(N,n,1), random_state=None)\n",
    "    else:\n",
    "        V=levy_stable.rvs(1/t, 1, loc=0, scale=np.cos(math.pi/(2*t))**t, size=(N,n,1), random_state=None)\n",
    "    return V\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def Gumbel_Marshall_Olkin_iterated_numba(V,d,t):\n",
    "    n = V.shape[1]\n",
    "    X=npr.exponential(1,size=(N,n,d))\n",
    "    G=np.empty_like(X)\n",
    "    for k in numba.prange(N):\n",
    "        for i in numba.prange(n):\n",
    "            for j in numba.prange(d):\n",
    "                G[k,i,j] = np.exp(  -(X[k,i,j]/V[k,i,0]**(1/t)  ))\n",
    "    return G\n",
    "                                                        \n",
    "######## Geisser-Mantel Model - @numba.njit\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def my_mean_numba(a):\n",
    "    out = np.empty((1,a.shape[1]))\n",
    "    for j in numba.prange(a.shape[1]):\n",
    "        out[0,j] = np.sum(a[:,j])/a.shape[0]\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def empirical_cov_numba(G): \n",
    "    d=G.shape[1]\n",
    "    n=G.shape[0]\n",
    "    M=np.empty((1,d)) \n",
    "    M[0,:]=my_mean_numba(G)[0,:] # same as M[0,:]=np.mean(G,axis=0)\n",
    "    I = np.ones((n,1))\n",
    "    out=np.dot( np.transpose(G-np.dot(I,M)), G-np.dot(I,M) )\n",
    "    return (1/(n))*out # n or n-1 ? the case n matches with scikit-learn empirical_covariance function\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def pairwise_corr_numba_numba(G,p,m): # G is a (p+m)*p real matrix\n",
    "    U = empirical_cov_numba(G) # d*d matrix\n",
    "    T = np.tril(U,-1) # set to 0 the upper triangular part of the square matrix U, including the diagonal\n",
    "    T=T.flatten() # flatten the matrix to a row vector\n",
    "    A = np.nonzero(T) # mask of indices giving nonzero values of T\n",
    "    out = T[A] # 1*d array of shape (d,) \n",
    "    return np.reshape(out, (1,int(p*(p-1)/2))) # reshaping to get an array (1,d) \n",
    "\n",
    "@numba.njit(parallel=False, fastmath=True) # Cannot set parallel=True because of issues with slicing\n",
    "def Geisser_Mantel_numba(G_n,n,p,m): \n",
    "    X = np.empty( (n,int(p*(p-1)/2)))\n",
    "    for k in numba.prange(n):\n",
    "        X[k,:] = pairwise_corr_numba_numba(G_n[k,:],p,m)\n",
    "    return X\n",
    "\n",
    "@numba.njit(parallel=False, fastmath=True)\n",
    "def Geisser_Mantel_iterated_numba(G_N,N,n,p,m): # d=p*(p-1)/2 \n",
    "    d = int(p*(p-1)/2)\n",
    "    X = np.empty((N,n,d))\n",
    "    for k in numba.prange(N):\n",
    "        X[k,:,:] = Geisser_Mantel_numba(G_N[k,:,:,:],n,p,m)\n",
    "    return X\n",
    "\n",
    "\n",
    "######## Elliptical model: Gaussian vector with determined Kendall's tau L^2 norm - no njit\n",
    "\n",
    "@numba.jit(parallel=True, fastmath=True) \n",
    "def iterated_gaussian_vector_sample(N,n,d,tau):\n",
    "    p = math.sin((math.pi/2)*math.sqrt((2*tau)/(d*(d-1))))\n",
    "    cov = p*np.ones((d,d))\n",
    "    np.fill_diagonal(cov, 1)\n",
    "    return npr.multivariate_normal(np.zeros(d),cov,size=(N,n))\n",
    "\n",
    "####### Banded model with different band structure\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True) \n",
    "def cov_matrix_banded(d,h_cov,rho):\n",
    "    cov = 0.25*np.ones((d,d))\n",
    "    np.fill_diagonal(cov, 1)\n",
    "    for i in numba.prange(d):\n",
    "        for j in numba.prange(d):\n",
    "            if i>=h_cov+j or j>=h_cov+i:\n",
    "                cov[i,j]=0\n",
    "    return cov        \n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True) \n",
    "def cov_matrix_ar1(d,rho):\n",
    "    cov = np.ones((d,d))\n",
    "    for i in numba.prange(d):\n",
    "        for j in numba.prange(d):\n",
    "            cov[i,j] = rho**(np.absolute(i-j))\n",
    "    return cov \n",
    "\n",
    "def cov_matrix_block(d,rho):\n",
    "    d2=np.floor(d/5)\n",
    "    A=np.identity(int(np.floor(d/5)))\n",
    "    B=rho*np.ones((5,5))\n",
    "    np.fill_diagonal(B, 1)\n",
    "    return np.kron(A,B)\n",
    "\n",
    "def iterated_banded_gaussian_sample(N,n,d,cov_matrix): # e.g., cov_matrix = cov_matrix_banded(d,h_cov)\n",
    "    return npr.multivariate_normal(np.zeros(d),cov_matrix,size=(N,n))\n",
    "\n",
    "def iterated_nonlinear_gaussian_sample(N,n,d):\n",
    "    G=npr.multivariate_normal(np.zeros(int(np.floor(d/5))),np.identity(int(np.floor(d/5))),size=(N,n))\n",
    "    G1=np.append(G, np.sin(2*np.pi*G), axis=2)\n",
    "    G2=np.append(G1, np.cos(2*np.pi*G), axis=2)\n",
    "    G3=np.append(G2, np.sin(4*np.pi*G), axis=2)\n",
    "    out=np.append(G3, np.cos(4*np.pi*G), axis=2)\n",
    "    return out\n",
    "\n",
    "######## Truncated Romano-Siegel Model, Section 4.2 of Genest and RÃ©millard (2004) - pairwise indep but not jointly indep\n",
    "\n",
    "def Romano_Siegel_iterated_data(N,n):\n",
    "    Z = npr.normal(0,1,size=(N,n,5))\n",
    "    for k in range(N):\n",
    "        for i in range(n):\n",
    "            Z[k,i,0]= np.absolute(Z[k,i,0])*np.sign(Z[k,i,1]*Z[k,i,2])\n",
    "            Z[k,i,4]= Z[k,i,3]/2 + np.sqrt(3)*Z[k,i,4]/2\n",
    "    return Z\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def Romano_Siegel_Numba_iterated_data(g,N,n): #g = npr.normal(0,1,size=(N,n,5))\n",
    "    for k in numba.prange(N):\n",
    "        for i in numba.prange(n):\n",
    "            g[k,i,0]= np.absolute(g[k,i,0])*np.sign(g[k,i,1]*g[k,i,2])\n",
    "            g[k,i,4]= g[k,i,3]/2 + np.sqrt(3)*g[k,i,4]/2\n",
    "    return g\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def Trunc_Romano_Siegel_Numba_iterated_data(g,N,n): #g = npr.normal(0,1,size=(N,n,3))\n",
    "    for k in numba.prange(N):\n",
    "        for i in numba.prange(n):\n",
    "            g[k,i,0]= np.absolute(g[k,i,0])*np.sign(g[k,i,1]*g[k,i,2])\n",
    "    return g\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def Trunc_d_Romano_Siegel_Numba_iterated_data(g,N,n,p): #g = npr.normal(0,1,size=(N,n,3*p))\n",
    "    for k in numba.prange(N):\n",
    "        for i in numba.prange(n):\n",
    "            for j in numba.prange(p):\n",
    "                g[k,i,3*j+0]= np.absolute(g[k,i,3*j+0])*np.sign(g[k,i,3*j+1]*g[k,i,3*j+2])\n",
    "    return g\n",
    "\n",
    "############################################################### Section 2: Computing the statistics - @numba.njit\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def rank(U):\n",
    "    R = np.empty_like(U)\n",
    "    for j in numba.prange(U.shape[1]):\n",
    "        R[:, j] = np.argsort(np.argsort(U[:, j]))+1\n",
    "    return R\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def I_pij(U): # Giving a data sample U of size n*d, return the 3D-array of the elementary block I^{(p)}_{i,j}\n",
    "    d = U.shape[1]\n",
    "    n = U.shape[0]\n",
    "    I = np.empty((d,n,n))\n",
    "    R = rank(U)\n",
    "    for p in numba.prange(0,d):\n",
    "        for i in numba.prange(0,n):\n",
    "            for j in numba.prange(0,n):\n",
    "                I[p,i,j] = 1/3 + 1/(6*n) + (R[i,p]*(R[i,p]-1))/(2*n*(n+1)) + (R[j,p]*(R[j,p]-1))/(2*n*(n+1)) - max(R[i,p],R[j,p])/(n+1)\n",
    "    return I\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def raw_statistics_234(U): # U data sample of size n*d\n",
    "    S_2 = 0\n",
    "    S_3 = 0\n",
    "    S_4 = 0\n",
    "    I = I_pij(U)\n",
    "    d = I.shape[0]\n",
    "    n = I.shape[1]\n",
    "    out = np.empty(3)\n",
    "    for p in numba.prange(0,d):\n",
    "        for q in numba.prange(0,p):\n",
    "            S_2 += (1/n)*np.sum(np.multiply(I[p,:,:],I[q,:,:]))- 1/36 + 1/(36*n)\n",
    "            for r in numba.prange(0,q): \n",
    "                S_3 += (1/n)*np.sum(np.multiply(np.multiply(I[p,:,:],I[q,:,:]),I[r,:,:])) - 1/(108*n**2) + 1/(72*n) - 1/216\n",
    "                # S_3 += (1/n)*np.sum(np.multiply(np.multiply(I[p,:,:],I[q,:,:]),I[r,:,:])) - (n-1)*(n-2)/(216*n*n)\n",
    "                for s in numba.prange(0,r):\n",
    "                        S_4 += (1/n)*np.sum(np.multiply(np.multiply(np.multiply(I[p,:,:],I[q,:,:]),I[r,:,:]),I[s,:,:]))  - ((n - 1)*(n**2 - 3*n + 3))/(1296*n**3)\n",
    "    out[0] = S_2\n",
    "    out[1] = S_3\n",
    "    out[2] = S_4\n",
    "    return out # np.array of shape (3,) representing (S2,S3,S4)\n",
    "                       \n",
    "def scaling_the_statistics(X,n,d,choice_scaling): # X=raw_statistics_234(U)\n",
    "    out=np.empty(5)\n",
    "    binom_2 = scipy.special.binom(d,2)\n",
    "    binom_3 = scipy.special.binom(d,3)\n",
    "    binom_4 = scipy.special.binom(d,4)\n",
    "    variance_2 = ((n-2)*(n-2)*(n-1)*(8*n+1))/(32400*n*n*(n+1)*(n+1))\n",
    "    scaling_finite_2 = 1/math.sqrt(variance_2*binom_2)\n",
    "    scaling_2 = 90/math.sqrt(2*binom_2)\n",
    "    variance_3 = (n-2)*(n-1)*(16*n - 96 + 359/n - 269/n**2 - 963/n**3 - 370/n**4)/(5832000*(n+1)**3) \n",
    "    scaling_finite_3 = 1/math.sqrt(variance_3*binom_3)\n",
    "    scaling_3 = 90*math.sqrt(90)/math.sqrt(2*binom_3)\n",
    "    scaling_4 = (90**2)/math.sqrt(2*binom_4)\n",
    "    scaling_finite_4 = scaling_4\n",
    "    if choice_scaling == 1: #finite variance scaling\n",
    "        out[0] = scaling_finite_2*X[0]\n",
    "        out[1] = scaling_finite_3*X[1]\n",
    "        out[2] = scaling_finite_4*X[3]\n",
    "        out[3] = out[0]+out[1]\n",
    "        out[4] = out[0]+out[1]+out[2]\n",
    "    else : #theoretical/asymptotic scaling\n",
    "        out[0] = scaling_2*X[0]\n",
    "        out[1] = scaling_3*X[1]\n",
    "        out[2] = scaling_4*X[2]\n",
    "        out[3] = out[0]+out[1]\n",
    "        out[4] = out[0]+out[1]+out[2]\n",
    "    return out # np.array of length 5 representing (S2, S3, S4, T3, T4)-rescaled\n",
    "    \n",
    "############################################################### Section 3: Output\n",
    "\n",
    "########################################## Iterated Raw Statistics \n",
    "# without the \\sqrt{2} and \\sqrt{3} for T2 and T2\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def iterated_raw_statistics_234(iterated_data_sample): # iterated_data_sample is a (N,n,d)-array\n",
    "    N = iterated_data_sample.shape[0]\n",
    "    n = iterated_data_sample.shape[1]\n",
    "    d = iterated_data_sample.shape[2]\n",
    "    X = np.empty((N,3))\n",
    "    U = np.empty((n,d))\n",
    "    for k in numba.prange(N):\n",
    "        U = iterated_data_sample[k,:,:]\n",
    "        X[k,:] = raw_statistics_234(U)\n",
    "    return X # np.array of shape (N,3) with column: (S2, S3, S4)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def iterated_rescaled_statistics_234(X,n,binom_2,binom_3,binom_4,choice_scaling): #X is N*3 np.array\n",
    "    N=X.shape[0]\n",
    "    out=np.empty((N,5))\n",
    "    variance_2 = ((n-2)*(n-2)*(n-1)*(8*n+1))/(32400*n*n*(n+1)*(n+1))\n",
    "    scaling_finite_2 = 1/math.sqrt(variance_2*binom_2)\n",
    "    scaling_2 = 90/math.sqrt(2*binom_2)\n",
    "    variance_3 = (n-2)*(n-1)*(16*n - 96 + 359/n - 269/n**2 - 963/n**3 - 370/n**4)/(5832000*(n+1)**3) \n",
    "    scaling_finite_3 = 1/math.sqrt(variance_3*binom_3)\n",
    "    scaling_3 = 90*math.sqrt(90)/math.sqrt(2*binom_3)\n",
    "    scaling_4 = (90**2)/math.sqrt(2*binom_4)\n",
    "    scaling_finite_4 = scaling_4\n",
    "    for k in numba.prange(N):\n",
    "        if choice_scaling == 1: #finite variance scaling\n",
    "            out[k,0] = scaling_finite_2*X[k,0]\n",
    "            out[k,1] = scaling_finite_3*X[k,1]\n",
    "            out[k,2] = scaling_finite_4*X[k,3]\n",
    "            out[k,3] = out[k,0]+out[k,1]\n",
    "            out[k,4] = out[k,0]+out[k,1]+out[k,2]\n",
    "        else : #theoretical/asymptotic scaling\n",
    "            out[k,0] = scaling_2*X[k,0]\n",
    "            out[k,1] = scaling_3*X[k,1]\n",
    "            out[k,2] = scaling_4*X[k,2]\n",
    "            out[k,3] = out[k,0]+out[k,1]\n",
    "            out[k,4] = out[k,0]+out[k,1]+out[k,2]\n",
    "    return out # np.array of shape (N,5) with column: (S2, S3, S4, T3, T4)-rescaled\n",
    "\n",
    "######### Power \n",
    "\n",
    "def power(A,x):\n",
    "    B=A[A>x]\n",
    "    return B.size/A.shape[0]\n",
    "\n",
    "def Gaussian_power_for_each_columns_234(A):\n",
    "    X=np.empty((1,5))\n",
    "    for i in range(3):\n",
    "        X[0,i]=power(A[:,i],1.645) # 95-percentile of a N(0,1)\n",
    "    X[0,3]=power((1/np.sqrt(2))*(A[:,3]),1.645) \n",
    "    X[0,4]=power((1/np.sqrt(3))*(A[:,4]),1.645) \n",
    "    return X\n",
    "\n",
    "def Gaussian_power_for_each_columns_23_new(A):\n",
    "    X=np.empty((1,3))\n",
    "    for i in range(3):\n",
    "        X[0,i]=power(A[:,i],1.645) # 95-percentile of a N(0,1)\n",
    "    return X\n",
    "\n",
    "def CF_power_for_each_columns_234(A,d): # Cornish-Fisher\n",
    "    X=np.empty((1,5))\n",
    "    if d==4:\n",
    "        X[0,0]=power(A[:,0],1.858792) \n",
    "        X[0,1]=power(A[:,1],1.867722) \n",
    "        X[0,2]=power(A[:,2],1.938571) \n",
    "        X[0,3]=power((1/np.sqrt(2))*(A[:,3]),1.813631) \n",
    "        X[0,4]=power((1/np.sqrt(3))*(A[:,4]),1.821249)\n",
    "    if d==8:\n",
    "        X[0,0]=power(A[:,0],1.758067) \n",
    "        X[0,1]=power(A[:,1],1.719549) \n",
    "        X[0,2]=power(A[:,2],1.712121) \n",
    "        X[0,3]=power((1/np.sqrt(2))*(A[:,3]),1.712876) \n",
    "        X[0,4]=power((1/np.sqrt(3))*(A[:,4]),1.695521)\n",
    "    if d==16:\n",
    "        X[0,0]=power(A[:,0],1.702343) \n",
    "        X[0,1]=power(A[:,1],1.669482) \n",
    "        X[0,2]=power(A[:,2],1.658623) \n",
    "        X[0,3]=power((1/np.sqrt(2))*(A[:,3]),1.674184) \n",
    "        X[0,4]=power((1/np.sqrt(3))*(A[:,4]),1.663556)\n",
    "    if d==32:\n",
    "        X[0,0]=power(A[:,0],1.67375) \n",
    "        X[0,1]=power(A[:,1],1.653226) \n",
    "        X[0,2]=power(A[:,2],1.647974) \n",
    "        X[0,3]=power((1/np.sqrt(2))*(A[:,3]),1.658101) \n",
    "        X[0,4]=power((1/np.sqrt(3))*(A[:,4]),1.652684)\n",
    "    if d==64:\n",
    "        X[0,0]=power(A[:,0],1.659332) \n",
    "        X[0,1]=power(A[:,1],1.647753) \n",
    "        X[0,2]=power(A[:,2],1.645597) \n",
    "        X[0,3]=power((1/np.sqrt(2))*(A[:,3]),1.651016) \n",
    "        X[0,4]=power((1/np.sqrt(3))*(A[:,4]),1.648355)\n",
    "    if d==128:\n",
    "        X[0,0]=power(A[:,0],1.652099) \n",
    "        X[0,1]=power(A[:,1],1.645868) \n",
    "        X[0,2]=power(A[:,2],1.645035) \n",
    "        X[0,3]=power((1/np.sqrt(2))*(A[:,3]),1.647779) \n",
    "        X[0,4]=power((1/np.sqrt(3))*(A[:,4]),1.646482)\n",
    "    if d==256:\n",
    "        X[0,0]=power(A[:,0],1.648478) \n",
    "        X[0,1]=power(A[:,1],1.64521) \n",
    "        X[0,2]=power(A[:,2],1.644898) \n",
    "        X[0,3]=power((1/np.sqrt(2))*(A[:,3]),1.646262) \n",
    "        X[0,4]=power((1/np.sqrt(3))*(A[:,4]),1.645629)\n",
    "    return X\n",
    "\n",
    "def Romano_Siegel_index(x): \n",
    "    y=0\n",
    "    if x==4:\n",
    "        y=3\n",
    "    if x==8:\n",
    "        y=6\n",
    "    if x==16:\n",
    "        y=15\n",
    "    if x==32:\n",
    "        y=30\n",
    "    if x==64:\n",
    "        y=63\n",
    "    if x==128:\n",
    "        y=126\n",
    "    if x==256:\n",
    "        y=255\n",
    "    return y \n",
    "\n",
    "def Geisser_Mantel_index(x):\n",
    "    y=0\n",
    "    if x==4:\n",
    "        y=3\n",
    "    if x==8:\n",
    "        y=6\n",
    "    if x==16:\n",
    "        y=10\n",
    "    if x==32:\n",
    "        y=28\n",
    "    if x==64:\n",
    "        y=55\n",
    "    if x==128:\n",
    "        y=120\n",
    "    if x==256:\n",
    "        y=231\n",
    "    return y \n",
    "\n",
    "############ All-in-one: Sampling iterated data + Computing iterated statistics (raw and rescaled) + Tabulars\n",
    "\n",
    "def all_data_stat_iid234(N):\n",
    "    for n in [16,32,64,128]:\n",
    "        for d in [4,8,16,32,64,128,256]:\n",
    "            binom_2 = scipy.special.binom(d,2)\n",
    "            binom_3 = scipy.special.binom(d,3)\n",
    "            binom_4 = scipy.special.binom(d,4)\n",
    "            iterated_data_sample = npr.exponential(1,size=(N,n,d))\n",
    "            X=iterated_raw_statistics_234(iterated_data_sample)\n",
    "            pd.DataFrame(X).to_csv(\"Raw_iid_234{}.csv\".format((N,n,d)), header=False, index=False)\n",
    "            for choice_scaling in [0,1]:\n",
    "                A=iterated_rescaled_statistics_234(X,n,binom_2,binom_3,binom_4,choice_scaling)\n",
    "                pd.DataFrame(A).to_csv(\"GR_234_iid{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "    return 'done!'\n",
    "\n",
    "def total_power_iid_234(N,choice_scaling,CF):\n",
    "    X=np.empty((4,5,7))\n",
    "    mean = 1\n",
    "    for j in range(5):\n",
    "        for n in [16, 32, 64, 128]:\n",
    "            for d in [4,8,16,32,64,128,256]:\n",
    "                d2=int(math.log(d)/math.log(2))-2\n",
    "                n2=int(math.log(n)/math.log(2))-4\n",
    "                A=pd.read_csv('GR_234_iid{}.csv'.format((N,n,d,choice_scaling)),header=None)\n",
    "                if CF == 1:\n",
    "                    X[n2,j,d2]=CF_power_for_each_columns_234(A.values,d)[0,j]\n",
    "                else:\n",
    "                    X[n2,j,d2]=Gaussian_power_for_each_columns_234(A.values)[0,j]\n",
    "    A_1=X[0,:,:]\n",
    "    B=X[1,:,:]\n",
    "    C=X[2,:,:]\n",
    "    D=X[3,:,:]\n",
    "    out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "    if CF == 1:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_CF_iid_234{}.csv\".format((N,choice_scaling)), header=False, index=False)\n",
    "    else:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_iid_234{}.csv\".format((N,choice_scaling)), header=False, index=False)\n",
    "    return 100*out\n",
    "\n",
    "def all_data_stat_Gaussian_banded234(N,h_cov,banded_model):\n",
    "    for n in [60,100]:\n",
    "        for d in [50,100,200,400]:\n",
    "            binom_2 = scipy.special.binom(d,2)\n",
    "            binom_3 = scipy.special.binom(d,3)\n",
    "            binom_4 = scipy.special.binom(d,4)\n",
    "            if banded_model == 0:\n",
    "                cov_matrixx = cov_matrix_banded(d,h_cov,rho)\n",
    "            elif banded_model==1:\n",
    "                cov_matrixx = cov_matrix_ar1(d,rho)\n",
    "            else:\n",
    "                cov_matrixx = cov_matrix_block(d,rho)                \n",
    "            iterated_data_sample=iterated_gaussian_vector_sample(N,n,d,cov_matrixx)\n",
    "            X=iterated_raw_statistics_234(iterated_data_sample)\n",
    "            pd.DataFrame(X).to_csv(\"Raw_Statistics_Gaussian_Banded_234{}.csv\".format((N,n,d,h_cov,rho,banded_model)), header=False, index=False)            \n",
    "            for choice_scaling in [0,1]:\n",
    "                A=iterated_rescaled_statistics_234(X,n,binom_2,binom_3,binom_4,choice_scaling)\n",
    "                if banded_model == 0:\n",
    "                    pd.DataFrame(A).to_csv(\"GR234_Band{}.csv\".format((N,n,d,h_cov,rho,choice_scaling)),header=None)\n",
    "                elif banded_model==1:\n",
    "                    pd.DataFrame(A).to_csv(\"GR234_AR(1){}.csv\".format((N,n,d,rho,choice_scaling)),header=None)\n",
    "                else:\n",
    "                    pd.DataFrame(A).to_csv(\"GR234_Block{}.csv\".format((N,n,d,rho,choice_scaling)),header=None)    \n",
    "    return 'done!'\n",
    "\n",
    "def total_power_Gaussian_Banded_23(N,h_cov,rho,banded_model,choice_scaling):\n",
    "    X=np.empty((2,3,4))\n",
    "    mean = 1\n",
    "    for j in range(3):\n",
    "        for n in [60,100]:\n",
    "            for d in [50,100,200,400]:\n",
    "                if n==60:\n",
    "                    n2=0\n",
    "                elif n==100:\n",
    "                    n2=1\n",
    "                if d==50:\n",
    "                    d2=0\n",
    "                elif d==100:\n",
    "                    d2=1\n",
    "                elif d==200:\n",
    "                    d2=2\n",
    "                elif d==400:\n",
    "                    d2=3\n",
    "                if banded_model == 0:\n",
    "                    A=pd.read_csv(\"GR234_Band{}.csv\".format((N,n,d,h_cov,rho,choice_scaling)),header=None)\n",
    "                elif banded_model==1:\n",
    "                    A=pd.read_csv(\"GR234_AR(1){}.csv\".format((N,n,d,rho,choice_scaling)),header=None)\n",
    "                else:\n",
    "                    A=pd.read_csv(\"GR234_Block{}.csv\".format((N,n,d,rho,choice_scaling)),header=None)                    \n",
    "                Y=A.values\n",
    "                X[n2,j,d2]=Gaussian_power_for_each_columns_23_new(Y)[0,j]\n",
    "    A_1=X[0,:,:]\n",
    "    B=X[1,:,:]\n",
    "    out = np.concatenate((A_1,B),axis=0)\n",
    "    if banded_model == 0:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Band{}.csv\".format((N,h_cov,rho,choice_scaling)), header=False, index=False)\n",
    "    elif banded_model==1:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_AR(1){}.csv\".format((N,rho,choice_scaling)), header=False, index=False)\n",
    "    else:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Block_{}.csv\".format((N,rho,choice_scaling)), header=False, index=False)        \n",
    "    return 100*out \n",
    "\n",
    "def all_data_stat_inductive234(N):\n",
    "    for n in [16,32,64,128]:\n",
    "        for d in [4,8,16,32,64,128,256]:\n",
    "            binom_2 = scipy.special.binom(d,2)\n",
    "            binom_3 = scipy.special.binom(d,3)\n",
    "            binom_4 = scipy.special.binom(d,4)\n",
    "            initializing_normal_sample=npr.uniform(0,1,size=(N,n,2))\n",
    "            iterated_data_sample = inductive_model_iterated_numba(initializing_normal_sample,N,n,d)\n",
    "            X=iterated_raw_statistics_234(iterated_data_sample)\n",
    "            pd.DataFrame(X).to_csv(\"Raw_inductive_234{}.csv\".format((N,n,d)), header=False, index=False)\n",
    "            for choice_scaling in [0,1]:\n",
    "                A=iterated_rescaled_statistics_234(X,n,binom_2,binom_3,binom_4,choice_scaling)\n",
    "                pd.DataFrame(A).to_csv(\"GR_234_inductive{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "    return 'done!'\n",
    "\n",
    "def total_power_inductive_234(N,choice_scaling,CF):\n",
    "    X=np.empty((4,5,7))\n",
    "    for j in range(5):\n",
    "        for n in [16, 32, 64, 128]:\n",
    "            for d in [4,8,16,32,64,128,256]:\n",
    "                d2=int(math.log(d)/math.log(2))-2\n",
    "                n2=int(math.log(n)/math.log(2))-4\n",
    "                A=pd.read_csv('GR_234_inductive{}.csv'.format((N,n,d,choice_scaling)),header=None)\n",
    "                if CF == 1:   \n",
    "                    X[n2,j,d2]=CF_power_for_each_columns_234(A.values,d)[0,j]\n",
    "                else:\n",
    "                    X[n2,j,d2]=Gaussian_power_for_each_columns_234(A.values)[0,j]\n",
    "    A_1=X[0,:,:]\n",
    "    B=X[1,:,:]\n",
    "    C=X[2,:,:]\n",
    "    D=X[3,:,:]\n",
    "    out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "    if CF == 1:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_CF_Inductive_234{}.csv\".format((N,choice_scaling)), header=False, index=False)\n",
    "    else:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Inductive_234{}.csv\".format((N,choice_scaling)), header=False, index=False)\n",
    "    return 100*out \n",
    "\n",
    "def all_data_stat_Gaussian_Vector234(N):\n",
    "    for tau in [0.1,0.3,0.7]:\n",
    "        for n in [16,32,64,128]:\n",
    "            for d in [4,8,16,32,64,128,256]:\n",
    "                binom_2 = scipy.special.binom(d,2)\n",
    "                binom_3 = scipy.special.binom(d,3)\n",
    "                binom_4 = scipy.special.binom(d,4)\n",
    "                iterated_data_sample = iterated_gaussian_vector_sample(N,n,d,tau)\n",
    "                X=iterated_raw_statistics_234(iterated_data_sample)\n",
    "                pd.DataFrame(X).to_csv(\"Raw_Gaussian_Vector_234{}.csv\".format((N,n,d,tau)), header=False, index=False)\n",
    "                for choice_scaling in [0,1]:\n",
    "                    A=iterated_rescaled_statistics_234(X,n,binom_2,binom_3,binom_4,choice_scaling)\n",
    "                    pd.DataFrame(A).to_csv(\"GR_234_Gaussian_vector{}.csv\".format((N,n,d,tau,choice_scaling)), header=False, index=False)\n",
    "    return 'done!'\n",
    "\n",
    "def total_power_Gaussian_vector_234(N,tau,choice_scaling,CF):\n",
    "    X=np.empty((4,5,7))\n",
    "    for j in range(5):\n",
    "        for n in [16, 32, 64, 128]:\n",
    "            for d in [4,8,16,32,64,128,256]:\n",
    "                d2=int(math.log(d)/math.log(2))-2\n",
    "                n2=int(math.log(n)/math.log(2))-4\n",
    "                A=pd.read_csv('GR_234_Gaussian_vector{}.csv'.format((N,n,d,tau,choice_scaling)),header=None)\n",
    "                if CF == 1:\n",
    "                    X[n2,j,d2]=CF_power_for_each_columns_234(A.values,d)[0,j]\n",
    "                else:\n",
    "                    X[n2,j,d2]=Gaussian_power_for_each_columns_234(A.values)[0,j]    \n",
    "    A_1=X[0,:,:]\n",
    "    B=X[1,:,:]\n",
    "    C=X[2,:,:]\n",
    "    D=X[3,:,:]\n",
    "    out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "    if CF == 1:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_CF_Gaussian_Vector_234{}.csv\".format((N,tau,choice_scaling)), header=False, index=False)\n",
    "    else:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Gaussian_Vector_234{}.csv\".format((N,tau,choice_scaling)), header=False, index=False)\n",
    "    return 100*out   \n",
    "\n",
    "def all_data_stat_Geisser_Mantel234(N):\n",
    "    for n in [16,32,64,128]:\n",
    "        for d in [4,8,16,32,64,128,256]:\n",
    "            p = max(math.floor(math.sqrt(2*d)),3)\n",
    "            q=int(p*(p-1)/2)\n",
    "            m = math.floor(p/2)\n",
    "            G = npr.multivariate_normal(np.zeros(p),np.eye(p),size=p+m)\n",
    "            G_N = npr.multivariate_normal(np.zeros(p),np.eye(p),size=(int(N),int(n),int(p+m)))\n",
    "            binom_2 = scipy.special.binom(d,2)\n",
    "            binom_3 = scipy.special.binom(d,3)\n",
    "            binom_4 = scipy.special.binom(d,4)\n",
    "            iterated_data_sample=Geisser_Mantel_iterated_numba(G_N,N,n,p,m)\n",
    "            X=iterated_raw_statistics_234(iterated_data_sample)\n",
    "            pd.DataFrame(X).to_csv(\"Raw_Geisser_Mantel_234{}.csv\".format((N,n,q)), header=False, index=False)\n",
    "            for choice_scaling in [0,1]:\n",
    "                A=iterated_rescaled_statistics_234(X,n,binom_2,binom_3,binom_4,choice_scaling)\n",
    "                pd.DataFrame(A).to_csv(\"GR_234_Geisser_Mantel{}.csv\".format((N,n,q,choice_scaling)), header=False, index=False)\n",
    "    return 'done!'\n",
    "\n",
    "def total_power_Geisser_Mantel_234(N,choice_scaling,CF):\n",
    "    X=np.empty((4,5,7))\n",
    "    for j in range(5):\n",
    "        for n in [16, 32, 64, 128]:\n",
    "            for d in [4,8,16,32,64,128,256]: # [3,6,10,28,55,120,231]\n",
    "                d2=int(math.log(d)/math.log(2))-2\n",
    "                n2=int(math.log(n)/math.log(2))-4\n",
    "                A=pd.read_csv('GR_234_Geisser_Mantel{}.csv'.format((N,n,Geisser_Mantel_index(d),choice_scaling)),header=None)\n",
    "                if CF == 1:\n",
    "                    X[n2,j,d2]=CF_power_for_each_columns_234(A.values,d)[0,j]\n",
    "                else:\n",
    "                    X[n2,j,d2]=Gaussian_power_for_each_columns_234(A.values)[0,j]\n",
    "    A_1=X[0,:,:]\n",
    "    B=X[1,:,:]\n",
    "    C=X[2,:,:]\n",
    "    D=X[3,:,:]\n",
    "    out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "    if CF == 1:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_CF_Geisser_Mantel_234{}.csv\".format((N,choice_scaling)), header=False, index=False)\n",
    "    else:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Geisser_Mantel_234{}.csv\".format((N,choice_scaling)), header=False, index=False)        \n",
    "    return 100*out  \n",
    "\n",
    "def all_data_stat_Romano_Siegel234(N):\n",
    "    for n in [16,32,64,128]:\n",
    "        for d in [4,8,16,32,64,128,256]:\n",
    "            p=int(max(math.floor(d/3),1))\n",
    "            q=int(3*p)\n",
    "            g = npr.normal(0,1,size=(N,n,q))\n",
    "            iterated_data_sample=Trunc_d_Romano_Siegel_Numba_iterated_data(g,N,n,p)\n",
    "            binom_2 = scipy.special.binom(d,2)\n",
    "            binom_3 = scipy.special.binom(d,3)\n",
    "            binom_4 = scipy.special.binom(d,4)\n",
    "            X=iterated_raw_statistics_234(iterated_data_sample)\n",
    "            pd.DataFrame(X).to_csv(\"Raw_Trunc_d_Romano_Siegel_234{}.csv\".format((N,n,q)), header=False, index=False)\n",
    "            for choice_scaling in [0,1]:\n",
    "                A=iterated_rescaled_statistics_234(X,n,binom_2,binom_3,binom_4,choice_scaling)\n",
    "                pd.DataFrame(A).to_csv(\"GR_234_Trunc_d_Romano_Siegel{}.csv\".format((N,n,q,choice_scaling)), header=False, index=False)\n",
    "    return 'done!'\n",
    "\n",
    "def total_power_Romano_Siegel_234(N,choice_scaling,CF):\n",
    "    X=np.empty((4,5,7))\n",
    "    for j in range(5):\n",
    "        for n in [16, 32, 64, 128]:\n",
    "            for d in [4,8,16,32,64,128,256]: # [3,6,15,30,63,126,255]\n",
    "                d2=int(math.log(d)/math.log(2))-2\n",
    "                n2=int(math.log(n)/math.log(2))-4\n",
    "                A=pd.read_csv('GR_234_Trunc_d_Romano_Siegel{}.csv'.format((N,n,Romano_Siegel_index(d),choice_scaling)),header=None)\n",
    "                if CF == 1:\n",
    "                    X[n2,j,d2]=CF_power_for_each_columns_234(A.values,d)[0,j]\n",
    "                else:\n",
    "                    X[n2,j,d2]=Gaussian_power_for_each_columns_234(A.values)[0,j]\n",
    "    A_1=X[0,:,:]\n",
    "    B=X[1,:,:]\n",
    "    C=X[2,:,:]\n",
    "    D=X[3,:,:]\n",
    "    out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "    if CF == 1:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_CF_Romano_Siegel_234{}.csv\".format((N,choice_scaling)), header=False, index=False)\n",
    "    else:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Romano_Siegel_234{}.csv\".format((N,choice_scaling)), header=False, index=False)\n",
    "    return 100*out  \n",
    "\n",
    "############################################################### Section 4: Global variables\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#N = 500 # Number of iterations\n",
    "#n = 16\n",
    "#d = 16\n",
    "#choice_scaling = 0 # 1 is finite variance, 0 is for asymptotic/theoretical scaling\n",
    "\n",
    "\n",
    "### Pre-computations of the binomial coefficients \n",
    "#binom_2 = scipy.special.binom(d,2)\n",
    "#binom_3 = scipy.special.binom(d,3)\n",
    "#binom_4 = scipy.special.binom(d,4)\n",
    "\n",
    "### Pre-computations of the normalizing sequences\n",
    "#variance_2 = ((n-2)*(n-2)*(n-1)*(8*n+1))/(32400*n*n*(n+1)*(n+1))\n",
    "#scaling_finite_2 = 1/math.sqrt(variance_2*binom_2)\n",
    "#scaling_2 = 90/math.sqrt(2*binom_2)\n",
    "#variance_3 = (n-2)*(n-1)*(16*n - 96 + 359/n - 269/n**2 - 963/n**3 - 370/n**4)/(5832000*(n+1)**3) \n",
    "#scaling_finite_3 = 1/math.sqrt(variance_3*binom_3)\n",
    "#scaling_3 = 90*math.sqrt(90)/math.sqrt(2*binom_3)\n",
    "#scaling_4 = (90**2)/math.sqrt(2*binom_4)\n",
    "#scaling_finite_4 = scaling_4\n",
    "\n",
    "#mean = 1\n",
    "\n",
    "### Pre-sampling the intput data for Geisser-Mantel Numba Model\n",
    "#p = max(math.floor(math.sqrt(2*d)),3)\n",
    "#m = math.floor(p/2)\n",
    "#G = npr.multivariate_normal(np.zeros(p),np.eye(p),size=p+m)\n",
    "#G_N = npr.multivariate_normal(np.zeros(p),np.eye(p),size=(int(N),int(n),int(p+m)))\n",
    "#G_n = npr.multivariate_normal(np.zeros(p),np.eye(p),size=(n,p+m))\n",
    "\n",
    "### Pre-sampling the intput data for Marshall-Olkin Algorithm\n",
    "#t = 1\n",
    "#V = Stable_distrib_data(N,n,t)\n",
    "                                                                    \n",
    "### Pre-sampling the intput data for the inductive model\n",
    "#initializing_normal_sample=npr.uniform(0,1,size=(N,n,2))\n",
    "\n",
    "### Parameters for the Gaussian vector model\n",
    "#tau = 0.1\n",
    "#tau = 0.3\n",
    "#tau = 0.7\n",
    "\n",
    "###### Parameters for the Gaussian vector with banded structure (Band, AR(1), Block from Yao et al. 2018)\n",
    "# h_cov = 3\n",
    "# rho = 0.25\n",
    "\n",
    "#### Bandwidth of the banded test \n",
    "#h_1=h_cov # drives (p,q)\n",
    "#h_2=h_cov # drives (q,r)\n",
    "#h_3=h_cov # drives (p,r)\n",
    "\n",
    "# banded_model = 0 for Band structure Gaussian, 1 for AR(1)-structure, 2 for block structure\n",
    "# banded_model = 3 is for nonlinear Gaussian vector as in Example 6.3 in Yao et al. 2018\n",
    "\n",
    "############################################################### Section 5: Application\n",
    "########################### Section 5.1: Generating iterated data samples of size N*n*d\n",
    "                                  \n",
    "#iterated_data_sample=Tan_iterated_data(N,n,d)\n",
    "#p=int(max(math.floor(d/3),1))\n",
    "#g = npr.normal(0,1,size=(N,n,3*p))\n",
    "#iterated_data_sample = Trunc_d_Romano_Siegel_Numba_iterated_data(g,N,n,p)\n",
    "#iterated_data_sample = npr.normal(size=(N,n,d))\n",
    "#iterated_data_sample = npr.exponential(1,size=(N,n,d))\n",
    "#iterated_data_sample = npr.multivariate_normal(np.zeros(d),random_cov,size=(int(N),int(n),int(d)))\n",
    "#iterated_data_sample = npr.multivariate_normal(np.zeros(d),toeplitz_cov,size=((N),int(n)))\n",
    "#iterated_data_sample = inductive_model_iterated_numba(initializing_normal_sample,N,n,d)\n",
    "#iterated_data_sample = Gumbel_Marshall_Olkin_iterated_numba(V,d,t)\n",
    "#iterated_data_sample = Geisser_Mantel_iterated_numba(G_N,N,n,p,m)\n",
    "#iterated_data_sample = iterated_gaussian_vector_sample(N,n,d,tau)\n",
    "\n",
    "#all_data_stat_iid234(N)\n",
    "#all_data_stat_Romano_Siegel234(N)\n",
    "#all_data_stat_Geisser_Mantel234(N)\n",
    "#all_data_stat_Gaussian_Vector234(N)\n",
    "#all_data_stat_inductive234(N)\n",
    "\n",
    "########################### Section 5.3: Computing the statistics from the iterated data samples\n",
    "\n",
    "#X=iterated_raw_statistics_234(iterated_data_sample)\n",
    "#A=iterated_rescaled_statistics_234(X,n,binom_2,binom_3,binom_4,choice_scaling)\n",
    "                                  \n",
    "########################### Section 5.4: Displaying (histogram) and converting into Panda files the computed statistics\n",
    "\n",
    "#A_df = pd.DataFrame(A)   \n",
    "#A_df.hist()\n",
    "\n",
    "########################### Section 5.5: Storing in Excel files the iterated raw statistics N*2 or N*3 with column (S2,S3,S4)\n",
    "                                  \n",
    "#pd.DataFrame(X).to_csv(\"Raw_Normal_iid{}.csv\".format((N,n,d)), header=False, index=False)\n",
    "#pd.DataFrame(X).to_csv(\"Raw_Inductive{}.csv\".format((N,n,d)), header=False, index=False)\n",
    "#pd.DataFrame(X).to_csv(\"Raw_Random_Cov{}.csv\".format((N,n,d)), header=False, index=False)\n",
    "#pd.DataFrame(X).to_csv(\"Raw_Toeplitz{}.csv\".format((N,n,d)), header=False, index=False)\n",
    "#pd.DataFrame(X).to_csv(\"Raw_Gumbel{}.csv\".format((N,n,d,t)), header=False, index=False)\n",
    "#pd.DataFrame(X).to_csv(\"Raw_Geisser_Mantel{}.csv\".format((N,n,p,m)), header=False, index=False)\n",
    "#pd.DataFrame(X).to_csv(\"Raw_Gaussian_Vector{}.csv\".format((N,n,d,tau)), header=False, index=False)\n",
    "#pd.DataFrame(X).to_csv(\"Raw_Exponential_iid{}.csv\".format((N,n,d)), header=False, index=False)\n",
    "\n",
    "########################### Section 5.6: Storing in Excel files the final statistics (rescaled raw)\n",
    "                                  \n",
    "#pd.DataFrame(A).to_csv(\"GR_234_inductive{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Gumbel_Marshall_Olkin{}.csv\".format((N,n,d,t,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Geisser_Mantel{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Gaussian_vector{}.csv\".format((N,n,d,tau,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Exponential_iid{}.csv\".format((N,n,d,mean,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Random_Cov_Gauss{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Toeplitz_Cov_Gauss{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Tan{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Trunc_d_Romano_Siegel{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N = 500\n",
    "#choice_scaling = 0\n",
    "#CF = 1\n",
    "#tau1 = 0.1\n",
    "#tau2 = 0.3\n",
    "#tau3 = 0.7\n",
    "#total_power_iid_234(N,choice_scaling,CF)\n",
    "#total_power_Gaussian_vector_234(N,tau1,choice_scaling,CF)\n",
    "#total_power_Gaussian_vector_234(N,tau2,choice_scaling,CF)\n",
    "#total_power_Gaussian_vector_234(N,tau3,choice_scaling,CF)\n",
    "#total_power_inductive_234(N,choice_scaling,CF)\n",
    "#total_power_Geisser_Mantel_234(N,choice_scaling,CF)\n",
    "#total_power_Romano_Siegel_234(N,choice_scaling,CF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Banded Statistics\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def banded_raw_statistics_2(U,h): # U data sample of size n*d \n",
    "    S_2 = 0\n",
    "    S_3 = 0\n",
    "    S_4 = 0\n",
    "    I = I_pij(U)\n",
    "    d = I.shape[0]\n",
    "    n = I.shape[1]\n",
    "    out = np.empty(2)\n",
    "    for p in numba.prange(0,d):\n",
    "        for q in numba.prange(0,p):\n",
    "            if p>=h+q: #or q>=h+p:\n",
    "                S_2 += (1/n)*np.sum(np.multiply(I[p,:,:],I[q,:,:]))- 1/36 + 1/(36*n)\n",
    "    return S_2\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def banded_raw_statistics_3(U,h_1,h_2,h_3): # U data sample of size n*d \n",
    "    # h_1 drives the distance between (p,q), h_2 for (q,r) and h_3 for (p,r)\n",
    "    S_2 = 0\n",
    "    S_3 = 0\n",
    "    S_4 = 0\n",
    "    I = I_pij(U)\n",
    "    d = I.shape[0]\n",
    "    n = I.shape[1]\n",
    "    out = np.empty(2)\n",
    "    for p in numba.prange(0,d):\n",
    "        for q in numba.prange(0,p):\n",
    "            if p>=h_1+q: #or q>=h_1+p:\n",
    "                for r in numba.prange(0,q): \n",
    "                    if q>=h_2+r and p>=h_3+r:\n",
    "                        S_3 += (1/n)*np.sum(np.multiply(np.multiply(I[p,:,:],I[q,:,:]),I[r,:,:])) - 1/(108*n**2) + 1/(72*n) - 1/216 \n",
    "                        # S_3 += (1/n)*np.sum(np.multiply(np.multiply(I[p,:,:],I[q,:,:]),I[r,:,:])) - (n-1)*(n-2)/(216*n*n)\n",
    "\n",
    "    return S_3 \n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def banded_raw_statistics_23(U,h_1,h_2,h_3): # U data sample of size n*d \n",
    "    # h_1 drives the distance between (p,q), h_2 for (q,r) and h_3 for (p,r)\n",
    "    S_2 = 0\n",
    "    S_3 = 0\n",
    "    S_4 = 0\n",
    "    I = I_pij(U)\n",
    "    d = I.shape[0]\n",
    "    n = I.shape[1]\n",
    "    out = np.empty(2)\n",
    "    for p in numba.prange(0,d):\n",
    "        for q in numba.prange(0,p):\n",
    "            if p>=h_1+q: #or q>=h_1+p:\n",
    "                S_2 += (1/n)*np.sum(np.multiply(I[p,:,:],I[q,:,:]))- 1/36 + 1/(36*n)\n",
    "                for r in numba.prange(0,q): \n",
    "                    if q>=h_2+r and p>=h_3+r:\n",
    "                        S_3 += (1/n)*np.sum(np.multiply(np.multiply(I[p,:,:],I[q,:,:]),I[r,:,:])) - 1/(108*n**2) + 1/(72*n) - 1/216 \n",
    "                        # S_3 += (1/n)*np.sum(np.multiply(np.multiply(I[p,:,:],I[q,:,:]),I[r,:,:])) - (n-1)*(n-2)/(216*n*n)\n",
    "    out[0] = S_2\n",
    "    out[1] = S_3\n",
    "    return out # np.array of shape (2,) representing (S2,S3)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def banded_cardinal_23(d,h_1,h_2,h_3): # computes the cardinal of all ordered integer pairs and triples with\n",
    "    # bandwidth condition driven by (h_1,h_2,h_3)\n",
    "    out2 = np.zeros((d,d))\n",
    "    out3 = np.zeros((d,d,d))\n",
    "    out = np.zeros(2)\n",
    "    for p in numba.prange(0,d):\n",
    "        for q in numba.prange(0,p):\n",
    "            if p>=h_1+q: #or q>=h_1+p:\n",
    "                out2[p,q] = 1\n",
    "                for r in numba.prange(0,q): \n",
    "                    if q>=h_2+r and p>=h_3+r:\n",
    "                        out3[p,q,r] = 1\n",
    "    out[0]=np.sum(out2) # cardinal of all ordered pairs with distance between components driven by h[0] \n",
    "    out[1]=np.sum(out3) # cardinal of all ordered triples with pairwise distance condition driven by h\n",
    "    return out \n",
    "\n",
    "def banded_rescaled_statistics_2(X,n,d,h,choice_scaling): # X=banded_raw_statistics_2(U,h)\n",
    "    # U data sample of shape (n,d)\n",
    "    binom_2 = banded_cardinal_23(d,h,h,h)[0]\n",
    "    variance_2 = ((n-2)*(n-2)*(n-1)*(8*n+1))/(32400*n*n*(n+1)*(n+1))\n",
    "    scaling_finite_2 = 1/math.sqrt(variance_2*binom_2)\n",
    "    scaling_2 = 90/math.sqrt(2*binom_2)\n",
    "    if choice_scaling == 1: #finite variance scaling\n",
    "        out = scaling_finite_2*X\n",
    "    else : #theoretical/asymptotic scaling\n",
    "        out = scaling_2*X\n",
    "    return out # (S2)-rescaled according to the 'banded scaling' \n",
    "\n",
    "def banded_rescaled_statistics_3(X,n,d,h_1,h_2,h_3,choice_scaling): # X=banded_raw_statistics_3(U,h_1,h_2,h_3)\n",
    "    # U data sample of shape (n,d)\n",
    "    binom_3 = banded_cardinal_23(d,h_1,h_2,h_3)[1]\n",
    "    variance_3 = (n-2)*(n-1)*(16*n - 96 + 359/n - 269/n**2 - 963/n**3 - 370/n**4)/(5832000*(n+1)**3) \n",
    "    scaling_finite_3 = 1/math.sqrt(variance_3*binom_3)\n",
    "    scaling_3 = 90*math.sqrt(90)/math.sqrt(2*binom_3)\n",
    "    if choice_scaling == 1: #finite variance scaling\n",
    "        out = scaling_finite_3*X\n",
    "    else : #theoretical/asymptotic scaling\n",
    "        out = scaling_3*X\n",
    "    return out # (S3)-rescaled according to the 'banded scaling' \n",
    "\n",
    "def banded_rescaled_statistics_23(X,n,d,h_1,h_2,h_3,choice_scaling): # X=banded_raw_statistics_23(U,h_1,h_2,h_3)\n",
    "    # U data sample of shape (n,d)\n",
    "    out=np.empty(3)\n",
    "    cardinal = banded_cardinal_23(d,h_1,h_2,h_3)\n",
    "    binom_2 = cardinal[0]\n",
    "    binom_3 = cardinal[1]\n",
    "    variance_2 = ((n-2)*(n-2)*(n-1)*(8*n+1))/(32400*n*n*(n+1)*(n+1))\n",
    "    scaling_finite_2 = 1/math.sqrt(variance_2*binom_2)\n",
    "    scaling_2 = 90/math.sqrt(2*binom_2)\n",
    "    variance_3 = (n-2)*(n-1)*(16*n - 96 + 359/n - 269/n**2 - 963/n**3 - 370/n**4)/(5832000*(n+1)**3) \n",
    "    scaling_finite_3 = 1/math.sqrt(variance_3*binom_3)\n",
    "    scaling_3 = 90*math.sqrt(90)/math.sqrt(2*binom_3)\n",
    "    if choice_scaling == 1: #finite variance scaling\n",
    "        out[0] = scaling_finite_2*X[0]\n",
    "        out[1] = scaling_finite_3*X[1]\n",
    "        out[2] = (1/np.sqrt(2))*(out[0]+out[1])\n",
    "    else : #theoretical/asymptotic scaling\n",
    "        out[0] = scaling_2*X[0]\n",
    "        out[1] = scaling_3*X[1]\n",
    "        out[2] = (1/np.sqrt(2))*(out[0]+out[1])\n",
    "    return out # np.array of length 3 representing (S2, S3, T3)-rescaled according to the 'banded scaling' \n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def iterated_banded_raw_statistics_23(iterated_data_sample,h_1,h_2,h_3): # iterated_data_sample is a (N,n,d)-array\n",
    "    N = iterated_data_sample.shape[0]\n",
    "    n = iterated_data_sample.shape[1]\n",
    "    d = iterated_data_sample.shape[2]\n",
    "    X = np.empty((N,2))\n",
    "    U = np.empty((n,d))\n",
    "    for k in numba.prange(N):\n",
    "        U = iterated_data_sample[k,:,:]\n",
    "        X[k,:] = banded_raw_statistics_23(U,h_1,h_2,h_3)\n",
    "    return X # np.array of shape (N,2) with column: (S2, S3)\n",
    "\n",
    "def all_data_banded_stat_banded_23(N,h_cov,h_1,h_2,h_3,rho,banded_model,choice_scaling): # h_cov = 3 #rho = 0.25\n",
    "    # banded_model = 0 for Band structure Gaussian, 1 for AR(1)-structure, 2 for block structure\n",
    "    # banded_model = 3 is for nonlinear Gaussian vector as in Example 6.3 in Yao et al. 2018\n",
    "    for n in [60,100]:\n",
    "        for d in [50,100,200,400]:\n",
    "            if banded_model == 0:\n",
    "                cov_matrixx = cov_matrix_banded(d,h_cov,rho)\n",
    "            elif banded_model==1:\n",
    "                cov_matrixx = cov_matrix_ar1(d,rho)\n",
    "            else:\n",
    "                cov_matrixx = cov_matrix_block(d,rho)                \n",
    "            iterated_data_sample=iterated_banded_gaussian_sample(N,n,d,cov_matrixx)\n",
    "            if banded_model == 0:\n",
    "                iterated_data_sample2=iterated_data_sample**(1/3)\n",
    "                iterated_data_sample3=iterated_data_sample**(3)\n",
    "            if banded_model == 3:\n",
    "                iterated_data_sample4=iterated_nonlinear_gaussian_sample(N,n,d)\n",
    "            X=iterated_banded_raw_statistics_23(iterated_data_sample,h_1,h_2,h_3)\n",
    "            if banded_model == 0:\n",
    "                X2=iterated_banded_raw_statistics_23(iterated_data_sample2,h_1,h_2,h_3)\n",
    "                X3=iterated_banded_raw_statistics_23(iterated_data_sample3,h_1,h_2,h_3)\n",
    "            if banded_model == 3:\n",
    "                X4=iterated_banded_raw_statistics_23(iterated_data_sample4,h_1,h_2,h_3)\n",
    "            pd.DataFrame(X).to_csv(\"Raw_Banded_Statistics_23{}.csv\".format((N,n,d,h_cov,rho,banded_model)), header=False, index=False)\n",
    "            if banded_model == 0:    \n",
    "                pd.DataFrame(X2).to_csv(\"Raw_Banded_Root_Statistics_23{}.csv\".format((N,n,d,h_cov,rho,banded_model)), header=False, index=False)  \n",
    "                pd.DataFrame(X3).to_csv(\"Raw_Banded_InvRoot_Statistics_23{}.csv\".format((N,n,d,h_cov,rho,banded_model)), header=False, index=False)            \n",
    "            if banded_model == 3:            \n",
    "                pd.DataFrame(X4).to_csv(\"Raw_Banded_Nonlinear_Statistics_23{}.csv\".format((N,n,d,h_cov)), header=False, index=False)            \n",
    "            A=np.empty((N,3))\n",
    "            A2=np.empty((N,3))\n",
    "            A3=np.empty((N,3))\n",
    "            A4=np.empty((N,3))\n",
    "            cardinal = banded_cardinal_23(d,h_cov,h_cov,h_cov)\n",
    "            binom_2 = cardinal[0]\n",
    "            binom_3 = cardinal[1]\n",
    "            variance_2 = ((n-2)*(n-2)*(n-1)*(8*n+1))/(32400*n*n*(n+1)*(n+1))\n",
    "            scaling_finite_2 = 1/math.sqrt(variance_2*binom_2)\n",
    "            scaling_2 = 90/math.sqrt(2*binom_2)\n",
    "            variance_3 = (n-2)*(n-1)*(16*n - 96 + 359/n - 269/n**2 - 963/n**3 - 370/n**4)/(5832000*(n+1)**3) \n",
    "            scaling_finite_3 = 1/math.sqrt(variance_3*binom_3)\n",
    "            scaling_3 = 90*math.sqrt(90)/math.sqrt(2*binom_3)\n",
    "            for k in numba.prange(N):\n",
    "                if choice_scaling == 1: #finite variance scaling\n",
    "                    A[k,0] = scaling_finite_2*X[k,0]\n",
    "                    A[k,1] = scaling_finite_3*X[k,1]\n",
    "                    A[k,2] = (1/np.sqrt(2))*(A[k,0]+A[k,1])\n",
    "                    if banded_model == 0:    \n",
    "                        A2[k,0] = scaling_finite_2*X2[k,0]\n",
    "                        A2[k,1] = scaling_finite_3*X2[k,1]\n",
    "                        A2[k,2] = (1/np.sqrt(2))*(A2[k,0]+A2[k,1])\n",
    "                        A3[k,0] = scaling_finite_2*X3[k,0]\n",
    "                        A3[k,1] = scaling_finite_3*X3[k,1]\n",
    "                        A3[k,2] = (1/np.sqrt(2))*(A3[k,0]+A3[k,1])\n",
    "                    if banded_model == 3:\n",
    "                        A4[k,0] = scaling_finite_2*X4[k,0]\n",
    "                        A4[k,1] = scaling_finite_3*X4[k,1]\n",
    "                        A4[k,2] = (1/np.sqrt(2))*(A4[k,0]+A4[k,1])\n",
    "                else : #theoretical/asymptotic scaling\n",
    "                    A[k,0] = scaling_2*X[k,0]\n",
    "                    A[k,1] = scaling_3*X[k,1]\n",
    "                    A[k,2] = (1/np.sqrt(2))*(A[k,0]+A[k,1])\n",
    "                    if banded_model == 0:    \n",
    "                        A2[k,0] = scaling_2*X2[k,0]\n",
    "                        A2[k,1] = scaling_3*X2[k,1]\n",
    "                        A2[k,2] = (1/np.sqrt(2))*(A2[k,0]+A2[k,1])\n",
    "                        A3[k,0] = scaling_2*X3[k,0]\n",
    "                        A3[k,1] = scaling_3*X3[k,1]\n",
    "                        A3[k,2] = (1/np.sqrt(2))*(A3[k,0]+A3[k,1])\n",
    "                    if banded_model == 3:\n",
    "                        A4[k,0] = scaling_2*X4[k,0]\n",
    "                        A4[k,1] = scaling_3*X4[k,1]\n",
    "                        A4[k,2] = (1/np.sqrt(2))*(A4[k,0]+A4[k,1])\n",
    "            if banded_model == 0:\n",
    "                pd.DataFrame(A).to_csv(\"Banded_Statistics_Band_23{}.csv\".format((N,n,d,h_cov,h_1,h_2,h_3,rho,choice_scaling)), header=False, index=False)\n",
    "                pd.DataFrame(A2).to_csv(\"Banded_Statistics_Band_Root_23{}.csv\".format((N,n,d,h_cov,h_1,h_2,h_3,rho,choice_scaling)), header=False, index=False)\n",
    "                pd.DataFrame(A3).to_csv(\"Banded_Statistics_Band_InvRoot_23{}.csv\".format((N,n,d,h_cov,h_1,h_2,h_3,rho,choice_scaling)), header=False, index=False)\n",
    "            elif banded_model==1:\n",
    "                pd.DataFrame(A).to_csv(\"Banded_Statistics_AR(1)_23{}.csv\".format((N,n,d,h_1,h_2,h_3,rho,choice_scaling)), header=False, index=False)\n",
    "            elif banded_model==2:\n",
    "                pd.DataFrame(A).to_csv(\"Banded_Statistics_Block_23{}.csv\".format((N,n,d,h_1,h_2,h_3,rho,choice_scaling)), header=False, index=False)   \n",
    "            elif banded_model ==3:\n",
    "                pd.DataFrame(A4).to_csv(\"Banded_Statistics_Nonlinear_23{}.csv\".format((N,n,d,h_1,h_2,h_3,choice_scaling)), header=False, index=False)   \n",
    "    return 'done!'\n",
    " \n",
    "def total_power_banded_23(N,h_cov,h_1,h_2,h_3,rho,banded_model,choice_scaling):\n",
    "    X=np.empty((2,3,4))\n",
    "    X2=np.empty((2,3,4))\n",
    "    mean = 1\n",
    "    for j in range(3):\n",
    "        for n in [60,100]:\n",
    "            for d in [50,100,200,400]:\n",
    "                if n==60:\n",
    "                    n2=0\n",
    "                elif n==100:\n",
    "                    n2=1\n",
    "                if d==50:\n",
    "                    d2=0\n",
    "                elif d==100:\n",
    "                    d2=1\n",
    "                elif d==200:\n",
    "                    d2=2\n",
    "                elif d==400:\n",
    "                    d2=3\n",
    "                if banded_model == 0:\n",
    "                    A=pd.read_csv(\"Banded_Statistics_Band_23{}.csv\".format((N,n,d,h_cov,h_1,h_2,h_3,rho,choice_scaling)),header=None)\n",
    "                    A2=pd.read_csv(\"Banded_Statistics_Band_Root_23{}.csv\".format((N,n,d,h_cov,h_1,h_2,h_3,rho,choice_scaling)),header=None)\n",
    "                    A3=pd.read_csv(\"Banded_Statistics_Band_InvRoot_23{}.csv\".format((N,n,d,h_cov,h_1,h_2,h_3,rho,choice_scaling)),header=None)\n",
    "                elif banded_model==1:\n",
    "                    A=pd.read_csv(\"Banded_Statistics_AR(1)_23{}.csv\".format((N,n,d,h_1,h_2,h_3,rho,choice_scaling)),header=None)\n",
    "                elif banded_model==2:\n",
    "                    A=pd.read_csv(\"Banded_Statistics_Block_23{}.csv\".format((N,n,d,h_1,h_2,h_3,rho,choice_scaling)),header=None)                    \n",
    "                elif banded_model==3:\n",
    "                     A=pd.read_csv(\"Banded_Statistics_Nonlinear_23{}.csv\".format((N,n,d,h_1,h_2,h_3,choice_scaling)),header=None)                                   \n",
    "                Y=A.values\n",
    "                X[n2,j,d2]=Gaussian_power_for_each_columns_23_new(Y)[0,j]\n",
    "                if banded_model == 0:\n",
    "                    Y2=A2.values\n",
    "                    X2[n2,j,d2]=Gaussian_power_for_each_columns_23_new(Y2)[0,j] \n",
    "                    Y3=A3.values\n",
    "                    X3[n2,j,d2]=Gaussian_power_for_each_columns_23_new(Y3)[0,j]  \n",
    "    A_1=X[0,:,:]\n",
    "    B=X[1,:,:]\n",
    "    out = np.concatenate((A_1,B),axis=0)\n",
    "    if banded_model == 0:\n",
    "        A2_1=X2[0,:,:]\n",
    "        B2=X2[1,:,:]\n",
    "        out2 = np.concatenate((A2_1,B2),axis=0)  \n",
    "        A3_1=X3[0,:,:]\n",
    "        B3=X3[1,:,:]\n",
    "        out3 = np.concatenate((A3_1,B3),axis=0) \n",
    "    if banded_model == 0:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Banded_Statistics_Band_23{}.csv\".format((N,h_cov,h_1,h_2,h_3,rho,choice_scaling)), header=False, index=False)\n",
    "        pd.DataFrame(out2).to_csv(\"Tabular_Banded_Statistics_Band_Root_23{}.csv\".format((N,h_cov,h_1,h_2,h_3,rho,choice_scaling)), header=False, index=False)\n",
    "        pd.DataFrame(out3).to_csv(\"Tabular_Banded_Statistics_Band_InvRoot_23{}.csv\".format((N,h_cov,h_1,h_2,h_3,rho,choice_scaling)), header=False, index=False)\n",
    "    elif banded_model==1:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Banded_Statistics_AR(1)_23{}.csv\".format((N,h_1,h_2,h_3,rho,choice_scaling)), header=False, index=False)\n",
    "    elif banded_model==2:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Banded_Statistics_Block_23{}.csv\".format((N,h_1,h_2,h_3,rho,choice_scaling)), header=False, index=False)        \n",
    "    elif banded_model==3:\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Banded_Statistics_Block_23{}.csv\".format((N,h_1,h_2,h_3,rho,choice_scaling)), header=False, index=False)                \n",
    "    return 100*out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Does not really work... why?\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def iterated_banded_rescaled_statistics_23(X,n,d,choice_scaling,h_1,h_2,h_3): #X is N*2 np.array\n",
    "    N=X.shape[0]\n",
    "    out=np.empty((N,3))\n",
    "    cardinal = banded_cardinal_23(d,h_1,h_2,h_3)\n",
    "    variance_2 = ((n-2)*(n-2)*(n-1)*(8*n+1))/(32400*n*n*(n+1)*(n+1))\n",
    "    scaling_finite_2 = 1/math.sqrt(variance_2*cardinal[0])\n",
    "    scaling_2 = 90/math.sqrt(2*cardinal[0])\n",
    "    variance_3 = (n-2)*(n-1)*(16*n - 96 + 359/n - 269/n**2 - 963/n**3 - 370/n**4)/(5832000*(n+1)**3) \n",
    "    scaling_finite_3 = 1/math.sqrt(variance_3*cardinal[1])\n",
    "    scaling_3 = 90*math.sqrt(90)/math.sqrt(2*cardinal[1])\n",
    "    for k in numba.prange(N):\n",
    "        if choice_scaling == 1: #finite variance scaling\n",
    "            out[k,0] = scaling_finite_2*X[k,0]\n",
    "            out[k,1] = scaling_finite_3*X[k,1]\n",
    "            out[k,2] = (1/np.sqrt(2))*(out[k,0]+out[k,1])\n",
    "        else : #theoretical/asymptotic scaling\n",
    "            out[k,0] = scaling_2*X[k,0]\n",
    "            out[k,1] = scaling_3*X[k,1]\n",
    "            out[k,2] = (1/np.sqrt(2))*(out[k,0]+out[k,1])\n",
    "            \n",
    "#########################################################################################\n",
    "\n",
    "#Size: Sample Z with parameters rho=0.3 h_cov=5 h=5 + h=10 and sample W=Z^{1/3}\n",
    "#Power: Sample Z with parameters rho=0.1 h_cov=20 h=5 + h=10 and sample W=Z^{1/3}\n",
    "\n",
    "###################\n",
    "\n",
    "N=500\n",
    "rho=0.3\n",
    "h_cov=5\n",
    "h_1=5\n",
    "h_2=5\n",
    "h_3=5\n",
    "banded_model=0\n",
    "choice_scaling=0\n",
    "all_data_banded_stat_banded_23(N,h_cov,h_1,h_2,h_3,rho,banded_model,choice_scaling)\n",
    "total_power_banded_23(N,h_cov,h_1,h_2,h_3,rho,banded_model,choice_scaling)\n",
    "\n",
    "###################\n",
    "\n",
    "N=500\n",
    "rho=0.1\n",
    "h_cov=20\n",
    "h_1=5\n",
    "h_2=5\n",
    "h_3=5\n",
    "banded_model=0\n",
    "choice_scaling=0\n",
    "all_data_banded_stat_banded_23(N,h_cov,h_1,h_2,h_3,rho,banded_model,choice_scaling)\n",
    "total_power_banded_23(N,h_cov,h_1,h_2,h_3,rho,banded_model,choice_scaling)\n",
    "\n",
    "###################\n",
    "\n",
    "N=500\n",
    "rho=0.3\n",
    "h_cov=5\n",
    "h_1=10\n",
    "h_2=10\n",
    "h_3=10\n",
    "banded_model=0\n",
    "choice_scaling=0\n",
    "all_data_banded_stat_banded_23(N,h_cov,h_1,h_2,h_3,rho,banded_model,choice_scaling)\n",
    "total_power_banded_23(N,h_cov,h_1,h_2,h_3,rho,banded_model,choice_scaling)\n",
    "\n",
    "###################\n",
    "\n",
    "N=500\n",
    "rho=0.1\n",
    "h_cov=20\n",
    "h_1=10\n",
    "h_2=10\n",
    "h_3=10\n",
    "banded_model=0\n",
    "choice_scaling=0\n",
    "all_data_banded_stat_banded_23(N,h_cov,h_1,h_2,h_3,rho,banded_model,choice_scaling)\n",
    "total_power_banded_23(N,h_cov,h_1,h_2,h_3,rho,banded_model,choice_scaling)\n",
    "\n",
    "###################\n",
    "\n",
    "N=500\n",
    "h_1=5\n",
    "h_2=5\n",
    "h_3=5\n",
    "banded_model=3\n",
    "choice_scaling=0\n",
    "all_data_banded_stat_banded_23(N,h_cov,h_1,h_2,h_3,rho,banded_model,choice_scaling)\n",
    "total_power_banded_23(N,h_cov,h_1,h_2,h_3,rho,banded_model,choice_scaling)\n",
    "\n",
    "###################\n",
    "\n",
    "N=500\n",
    "h_1=5\n",
    "h_2=5\n",
    "h_3=5\n",
    "banded_model=3\n",
    "choice_scaling=0\n",
    "all_data_banded_stat_banded_23(N,h_cov,h_1,h_2,h_3,rho,banded_model,choice_scaling)\n",
    "total_power_banded_23(N,h_cov,h_1,h_2,h_3,rho,banded_model,choice_scaling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Prostate and Healthy Datasets\n",
    "\n",
    "n = 167 # for Prostate_data\n",
    "n_h = 157 # for Healthy_data\n",
    "d = 218\n",
    "choice_scaling = 0 # 0 is for theoretical scaling and 1 for finite variance version\n",
    "#h_1 = 50 # bandwidth in [50,180]\n",
    "#h_2 = 50\n",
    "#h_3 = 50\n",
    "\n",
    "Normal_data = npr.normal(0,1,size=(n,d))\n",
    "Prostate_data = np.loadtxt('data_prostate.txt',delimiter=',')\n",
    "Healthy_data = np.loadtxt('data_healthy.txt',delimiter=',')\n",
    "\n",
    "################################################################################################################################################\n",
    "#X_p = banded_raw_statistics_23(Prostate_data,h_1,h_2,h_3)\n",
    "#X_h = banded_raw_statistics_23(Healthy_data,h_1,h_2,h_3) \n",
    "#pd.DataFrame(X_p).to_csv(\"Raw_23_Prostate{}.csv\".format((h_1,h_2,h_3)), header=False, index=False)\n",
    "#pd.DataFrame(X_h).to_csv(\"Raw_23_Healthy{}.csv\".format((h_1,h_2,h_3)), header=False, index=False) \n",
    "\n",
    "#A_p = banded_rescaled_statistics_23(X_p,n,d,h_1,h_2,h_3,choice_scaling)\n",
    "#A_h = banded_rescaled_statistics_23(X_h,n_h,d,h_1,h_2,h_3,choice_scaling)                                                                            \n",
    "#pd.DataFrame(A_p).to_csv(\"Banded_Statistics_23_Prostate{}.csv\".format((h_1,h_2,h_3,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A_h).to_csv(\"Banded_Statistics_23_Healthy{}.csv\".format((h_1,h_2,h_3,choice_scaling)), header=False, index=False)\n",
    "################################################################################################################################################\n",
    "\n",
    "x=50\n",
    "y2=180\n",
    "y3=110\n",
    "h_grid2=np.arange(x,y2,2)\n",
    "h_grid3=np.arange(x,y3,2)\n",
    "out_2p = np.empty(h_grid2.size)\n",
    "out_2h = np.empty(h_grid2.size)\n",
    "out_2n = np.empty(h_grid2.size)\n",
    "out_3p = np.empty(h_grid3.size)\n",
    "out_3h = np.empty(h_grid3.size)\n",
    "out_3n = np.empty(h_grid3.size)\n",
    "out_23p = np.empty((h_grid3.size,3))\n",
    "out_23h = np.empty((h_grid3.size,3))\n",
    "out_23n = np.empty((h_grid3.size,3))\n",
    "\n",
    "# banded_cardinal_23(d,h_1,h_2,h_3)[1] = 0 as soon as h larger than 108 when d is 218\n",
    "\n",
    "for h in h_grid2:\n",
    "    if 109>h:\n",
    "        X_3n = banded_raw_statistics_3(Normal_data,h,h,h)\n",
    "        X_3p = banded_raw_statistics_3(Prostate_data,h,h,h)\n",
    "        X_3h = banded_raw_statistics_3(Healthy_data,h,h,h)\n",
    "        X_23p = banded_raw_statistics_23(Prostate_data,h,h,h)\n",
    "        X_23h = banded_raw_statistics_23(Healthy_data,h,h,h)\n",
    "        X_23n = banded_raw_statistics_23(Normal_data,h,h,h)\n",
    "        out_3p[int((h-x)/2)] = banded_rescaled_statistics_3(X_3p,n,d,h,h,h,choice_scaling)\n",
    "        #pd.DataFrame(out_3p).to_csv(\"ProstateBandedStat3_h{}.csv\".format((h,choice_scaling)), header=False, index=False)\n",
    "        out_3h[int((h-x)/2)] = banded_rescaled_statistics_3(X_3h,n_h,d,h,h,h,choice_scaling) \n",
    "        #pd.DataFrame(out_3h).to_csv(\"HealthyBandedStat3_h{}.csv\".format((h,choice_scaling)), header=False, index=False)\n",
    "        out_3n[int((h-x)/2)] = banded_rescaled_statistics_3(X_3n,n_h,d,h,h,h,choice_scaling) \n",
    "        out_23p[int((h-x)/2),:] = banded_rescaled_statistics_23(X_23p,n,d,h,h,h,choice_scaling)\n",
    "        #pd.DataFrame(out_23p).to_csv(\"ProstateBandedStat23_h{}.csv\".format((h,choice_scaling)), header=False, index=False)\n",
    "        out_23h[int((h-x)/2),:] = banded_rescaled_statistics_23(X_23h,n_h,d,h,h,h,choice_scaling)\n",
    "        #pd.DataFrame(out_23h).to_csv(\"HealthyBandedStat23_h{}.csv\".format((h,choice_scaling)), header=False, index=False)\n",
    "        out_23n[int((h-x)/2),:] = banded_rescaled_statistics_23(X_23n,n_h,d,h,h,h,choice_scaling)\n",
    "    X_2p = banded_raw_statistics_2(Prostate_data,h)\n",
    "    X_2h = banded_raw_statistics_2(Healthy_data,h)\n",
    "    X_2n = banded_raw_statistics_2(Normal_data,h)\n",
    "    out_2p[int((h-x)/2)] = banded_rescaled_statistics_2(X_2p,n,d,h,choice_scaling)\n",
    "    #pd.DataFrame(out_2p).to_csv(\"ProstateBandedStat2_h{}.csv\".format((h,choice_scaling)), header=False, index=False)\n",
    "    out_2h[int((h-x)/2)] = banded_rescaled_statistics_2(X_2h,n_h,d,h,choice_scaling) \n",
    "    #pd.DataFrame(out_2h).to_csv(\"HealthyBandedStat2_h{}.csv\".format((h,choice_scaling)), header=False, index=False)\n",
    "    out_2n[int((h-x)/2)] = banded_rescaled_statistics_2(X_2n,n_h,d,h,choice_scaling) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt    \n",
    "legend_dict = { 'S2' : 'blue', 'S3' : 'green', 'T3' : 'red' }\n",
    "patchList = []\n",
    "for key in legend_dict:\n",
    "        data_key = mpatches.Patch(color=legend_dict[key], label=key)\n",
    "        patchList.append(data_key)\n",
    "plt.legend(handles=patchList)\n",
    "plt.plot(np.arange(x,y2,2),out_2p,color='blue')\n",
    "plt.plot(np.arange(x,y3,2),out_3p,color='green')\n",
    "plt.plot(np.arange(x,y3,2),out_23p[:,2],color='red')\n",
    "plt.title(\"Prostate cancer group\")\n",
    "plt.ylabel(\"Test statistic\")\n",
    "plt.xlabel(\"Bandwidth\")\n",
    "plt.savefig('Prostate.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt    \n",
    "legend_dict = { 'S2' : 'blue', 'S3' : 'green', 'T3' : 'red' }\n",
    "patchList = []\n",
    "for key in legend_dict:\n",
    "        data_key = mpatches.Patch(color=legend_dict[key], label=key)\n",
    "        patchList.append(data_key)\n",
    "plt.legend(handles=patchList)\n",
    "plt.plot(np.arange(x,y2,2),out_2h,color='blue')\n",
    "plt.plot(np.arange(x,y3,2),out_3h,color='green')\n",
    "plt.plot(np.arange(x,y3,2),out_23h[:,2],color='red')\n",
    "plt.title(\"Healthy group\")\n",
    "plt.ylabel(\"Test statistic\")\n",
    "plt.xlabel(\"Bandwidth\")\n",
    "plt.savefig('Healthy.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt    \n",
    "legend_dict = { 'S2' : 'blue', 'S3' : 'green', 'T3' : 'red' }\n",
    "patchList = []\n",
    "for key in legend_dict:\n",
    "        data_key = mpatches.Patch(color=legend_dict[key], label=key)\n",
    "        patchList.append(data_key)\n",
    "plt.legend(handles=patchList)\n",
    "plt.plot(np.arange(x,y2,2),out_2n,color='blue')\n",
    "plt.plot(np.arange(x,y3,2),out_3n,color='green')\n",
    "plt.plot(np.arange(x,y3,2),out_23n[:,2],color='red')\n",
    "plt.title(\"Independent Gaussian model\")\n",
    "plt.ylabel(\"Test statistic\")\n",
    "plt.xlabel(\"Bandwidth\")\n",
    "plt.savefig('Independent Gaussian model.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
