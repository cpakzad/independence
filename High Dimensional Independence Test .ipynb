{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "#%%timeit -n 1 -r 1 # time cost for 1 run with 1 loop\n",
    "\n",
    "############################################################### Packages\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from scipy.stats import levy_stable  \n",
    "from sklearn.covariance import empirical_covariance\n",
    "import matplotlib.pyplot as plt\n",
    "#import random\n",
    "import math \n",
    "import pandas as pd\n",
    "import scipy.special\n",
    "#from scipy.stats import rankdata\n",
    "import numba\n",
    "import timeit\n",
    "import time\n",
    "import warnings\n",
    "import psutil\n",
    "\n",
    "\n",
    "############################################################### Miscellenous\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "npr.seed(0)\n",
    "\n",
    "############################################################### Section 1: Generating N*n*d real matrix as data sample for different models\n",
    "\n",
    "\n",
    "######## Inductive model exhibing pairwise independence but not triplewise independence\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def inductive_model_iterated_numba(initializing_normal_sample,N,n,d):\n",
    "    X=np.empty((N,n,d))\n",
    "    for k in numba.prange(N):\n",
    "        for i in numba.prange(n):\n",
    "            X[k,i,0] = initializing_normal_sample[k,i,0]\n",
    "            X[k,i,1] = initializing_normal_sample[k,i,1]\n",
    "            for j in numba.prange(2,d):\n",
    "                if X[k,i,j-1]+X[k,i,j-2] > 1:\n",
    "                     X[k,i,j] =X[k,i,j-1]+X[k,i,j-2]-1\n",
    "                else:\n",
    "                    X[k,i,j] =X[k,i,j-1]+X[k,i,j-2]\n",
    "    return X\n",
    "\n",
    "######## d-variate Gumbel distribution. Algorithm by Marshall-Olkin - @numba.njit\n",
    "######## https://cran.r-project.org/web/packages/copula/vignettes/nacopula-pkg.pdf\n",
    "\n",
    "def Stable_distrib_data(N,n,t):\n",
    "    if t == 1:\n",
    "        V=levy_stable.rvs(1, 1, loc=1, scale=np.cos(math.pi/(2)), size=(N,n,1), random_state=None)\n",
    "    else:\n",
    "        V=levy_stable.rvs(1/t, 1, loc=0, scale=np.cos(math.pi/(2*t))**t, size=(N,n,1), random_state=None)\n",
    "    return V\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def Gumbel_Marshall_Olkin_iterated_numba(V,d,t):\n",
    "    n = V.shape[1]\n",
    "    X=npr.exponential(1,size=(N,n,d))\n",
    "    G=np.empty_like(X)\n",
    "    for k in numba.prange(N):\n",
    "        for i in numba.prange(n):\n",
    "            for j in numba.prange(d):\n",
    "                G[k,i,j] = np.exp(  -(X[k,i,j]/V[k,i,0]**(1/t)  ))\n",
    "    return G\n",
    "                                                        \n",
    "\n",
    "######## Geisser-Mantel Model - @numba.njit\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def my_mean_numba(a):\n",
    "    out = np.empty((1,a.shape[1]))\n",
    "    for j in numba.prange(a.shape[1]):\n",
    "        out[0,j] = np.sum(a[:,j])/a.shape[0]\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def empirical_cov_numba(G): \n",
    "    d=G.shape[1]\n",
    "    n=G.shape[0]\n",
    "    M=np.empty((1,d)) \n",
    "    M[0,:]=my_mean_numba(G)[0,:] # same as M[0,:]=np.mean(G,axis=0)\n",
    "    I = np.ones((n,1))\n",
    "    out=np.dot( np.transpose(G-np.dot(I,M)), G-np.dot(I,M) )\n",
    "    return (1/(n))*out # n or n-1 ? the case n matches with scikit-learn empirical_covariance function\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def pairwise_corr_numba_numba(G,p,m): # G is a (p+m)*p real matrix\n",
    "    U = empirical_cov_numba(G) # d*d matrix\n",
    "    T = np.tril(U,-1) # set to 0 the upper triangular part of the square matrix U, including the diagonal\n",
    "    T=T.flatten() # flatten the matrix to a row vector\n",
    "    A = np.nonzero(T) # mask of indices giving nonzero values of T\n",
    "    out = T[A] # 1*d array of shape (d,) \n",
    "    return np.reshape(out, (1,int(p*(p-1)/2))) # reshaping to get an array (1,d) \n",
    "\n",
    "@numba.njit(parallel=False, fastmath=True) # Cannot set parallel=True because of issues with slicing\n",
    "def Geisser_Mantel_numba(G_n,n,p,m): \n",
    "    X = np.empty( (n,int(p*(p-1)/2)))\n",
    "    for k in numba.prange(n):\n",
    "        X[k,:] = pairwise_corr_numba_numba(G_n[k,:],p,m)\n",
    "    return X\n",
    "\n",
    "@numba.njit(parallel=False, fastmath=True)\n",
    "def Geisser_Mantel_iterated_numba(G_N,N,n,p,m): # d=p*(p-1)/2 \n",
    "    d = int(p*(p-1)/2)\n",
    "    X = np.empty((N,n,d))\n",
    "    for k in numba.prange(N):\n",
    "        X[k,:,:] = Geisser_Mantel_numba(G_N[k,:,:,:],n,p,m)\n",
    "    return X\n",
    "\n",
    "\n",
    "######## Elliptical model: Gaussian vector with determined Kendall's tau L^2 norm - no njit\n",
    "\n",
    "@numba.jit(parallel=True, fastmath=True) \n",
    "def iterated_gaussian_vector_sample(N,n,d,tau):\n",
    "    p = math.sin((math.pi/2)*math.sqrt((2*tau)/(d*(d-1))))\n",
    "    cov = p*np.ones((d,d))\n",
    "    np.fill_diagonal(cov, 1)\n",
    "    return npr.multivariate_normal(np.zeros(d),cov,size=(N,n))\n",
    "\n",
    "    \n",
    "######## Truncated Romano-Siegel Model, Section 4.2 of Genest and Rémillard (2004) - pairwise indep but not jointly indep\n",
    "\n",
    "def Romano_Siegel_iterated_data(N,n):\n",
    "    Z = npr.normal(0,1,size=(N,n,5))\n",
    "    for k in range(N):\n",
    "        for i in range(n):\n",
    "            Z[k,i,0]= np.absolute(Z[k,i,0])*np.sign(Z[k,i,1]*Z[k,i,2])\n",
    "            Z[k,i,4]= Z[k,i,3]/2 + np.sqrt(3)*Z[k,i,4]/2\n",
    "    return Z\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def Romano_Siegel_Numba_iterated_data(g,N,n): #g = npr.normal(0,1,size=(N,n,5))\n",
    "    for k in numba.prange(N):\n",
    "        for i in numba.prange(n):\n",
    "            g[k,i,0]= np.absolute(g[k,i,0])*np.sign(g[k,i,1]*g[k,i,2])\n",
    "            g[k,i,4]= g[k,i,3]/2 + np.sqrt(3)*g[k,i,4]/2\n",
    "    return g\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def Trunc_Romano_Siegel_Numba_iterated_data(g,N,n): #g = npr.normal(0,1,size=(N,n,3))\n",
    "    for k in numba.prange(N):\n",
    "        for i in numba.prange(n):\n",
    "            g[k,i,0]= np.absolute(g[k,i,0])*np.sign(g[k,i,1]*g[k,i,2])\n",
    "    return g\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def Trunc_d_Romano_Siegel_Numba_iterated_data(g,N,n,p): #g = npr.normal(0,1,size=(N,n,3*p))\n",
    "    for k in numba.prange(N):\n",
    "        for i in numba.prange(n):\n",
    "            for j in numba.prange(p):\n",
    "                g[k,i,3*j+0]= np.absolute(g[k,i,3*j+0])*np.sign(g[k,i,3*j+1]*g[k,i,3*j+2])\n",
    "    return g\n",
    "\n",
    "############################################################### Section 2: Computing the statistics - @numba.njit\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def rank(U):\n",
    "    R = np.empty_like(U)\n",
    "    for j in numba.prange(U.shape[1]):\n",
    "        R[:, j] = np.argsort(np.argsort(U[:, j]))+1\n",
    "    return R\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def I_multiarray_Genest_Remillard(U): # Giving a data sample U of size n*d, return the 3D-array of the elementary block I^{(p)}_{i,j} from Genest-Rémillard statistic\n",
    "    d = U.shape[1]\n",
    "    n = U.shape[0]\n",
    "    J = np.empty((d,n,n))\n",
    "    R = rank(U)\n",
    "    for p in numba.prange(0,d):\n",
    "        for i in numba.prange(0,n):\n",
    "            for j in numba.prange(0,n):\n",
    "                J[p,i,j] = 1/3 + 1/(6*n) + (R[i,p]*(R[i,p]-1))/(2*n*(n+1)) + (R[j,p]*(R[j,p]-1))/(2*n*(n+1)) - max(R[i,p],R[j,p])/(n+1)\n",
    "    return J\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def raw_statistics_Genest_Remillard_234(U,binom_2,binom_3,binom_4): # U data sample of size n*d\n",
    "    S_2 = 0\n",
    "    S_3 = 0\n",
    "    S_4 = 0\n",
    "    J = I_multiarray_Genest_Remillard(U)\n",
    "    d = J.shape[0]\n",
    "    n = J.shape[1]\n",
    "    out = np.empty((1,3))\n",
    "    for p in numba.prange(0,d):\n",
    "        for q in numba.prange(0,p):\n",
    "            S_2 += (1/n)*np.sum(np.multiply(J[p,:,:],J[q,:,:]))- 1/36 + 1/(36*n)\n",
    "            for r in numba.prange(0,q):\n",
    "                S_3 += (1/n)*np.sum(np.multiply(np.multiply(J[p,:,:],J[q,:,:]),J[r,:,:])) - (n-1)*(n-2)/(216*n*n) \n",
    "                for s in numba.prange(0,r):\n",
    "                        S_4 += (1/n)*np.sum(np.multiply(np.multiply(np.multiply(J[p,:,:],J[q,:,:]),J[r,:,:]),J[s,:,:]))  - ((n - 1)*(n**2 - 3*n + 3))/(1296*n**3)\n",
    "    out[0,0] = S_2\n",
    "    out[0,1] = S_3\n",
    "    out[0,2] = S_4\n",
    "    return out # np.array of size 1*3 column (S2,S3,S4)\n",
    "                                  \n",
    "                                  \n",
    "############################################################### Section 3: Output data \n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def iterated_raw_statistics_GR_234_from_iterated_sample(iterated_data_sample,binom_2,binom_3,binom_4): # data_sample is a N*n*d matrix\n",
    "    N = iterated_data_sample.shape[0]\n",
    "    n = iterated_data_sample.shape[1]\n",
    "    d = iterated_data_sample.shape[2]\n",
    "    X = np.empty((N,3))\n",
    "    U = np.empty((n,d))\n",
    "    for k in numba.prange(N):\n",
    "        U = iterated_data_sample[k,:,:]\n",
    "        X[k,:] = raw_statistics_Genest_Remillard_234(U,binom_2,binom_3,binom_4).reshape((3))\n",
    "    return X # np.array of size N*3 with column: (S2, S3, S4)\n",
    "\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def scaled_statistics_GR_234_from_iterated(n,X,binom_2,binom_3,binom_4,choice_scaling): #X is N*3 np.array\n",
    "    out=np.empty((N,5))\n",
    "    variance_2 = ((n-2)*(n-2)*(n-1)*(8*n+1))/(32400*n*n*(n+1)*(n+1))\n",
    "    scaling_finite_2 = 1/math.sqrt(variance_2*binom_2)\n",
    "    scaling_2 = 90/math.sqrt(2*binom_2)\n",
    "    variance_3 = (n-2)*(n-1)*(16*n - 96 + 359/n - 269/n**2 - 963/n**3 - 370/n**4)/(5832000*(n+1)**3) \n",
    "    scaling_finite_3 = 1/math.sqrt(variance_3*binom_3)\n",
    "    scaling_3 = 90*math.sqrt(90)/math.sqrt(2*binom_3)\n",
    "    scaling_4 = (90**2)/math.sqrt(2*binom_4)\n",
    "    scaling_finite_4 = scaling_4\n",
    "    for k in numba.prange(N):\n",
    "        if choice_scaling == 1: #finite variance scaling\n",
    "            out[k,0] = scaling_finite_2*X[k,0]\n",
    "            out[k,1] = scaling_finite_3*X[k,1]\n",
    "            out[k,2] = scaling_finite_4*X[k,3]\n",
    "            out[k,3] = out[k,0]+out[k,1]\n",
    "            out[k,4] = out[k,0]+out[k,1]+out[k,2]\n",
    "        else : #theoretical/asymptotic scaling\n",
    "            out[k,0] = scaling_2*X[k,0]\n",
    "            out[k,1] = scaling_3*X[k,1]\n",
    "            out[k,2] = scaling_4*X[k,2]\n",
    "            out[k,3] = out[k,0]+out[k,1]\n",
    "            out[k,4] = out[k,0]+out[k,1]+out[k,2]\n",
    "    return out # np.array of size N*5 with column: (S2, S3, S4, T3, T4)-rescaled\n",
    "                        \n",
    "                                  \n",
    "\n",
    "############ All-in-one\n",
    "\n",
    "\n",
    "def all_data_exponential234(N,mean):\n",
    "    for n in [16,32,64,128]:\n",
    "        for d in [4,8,16,32,64,256]:\n",
    "            binom_2 = scipy.special.binom(d,2)\n",
    "            binom_3 = scipy.special.binom(d,3)\n",
    "            binom_4 = scipy.special.binom(d,4)\n",
    "            iterated_data_sample = npr.exponential(1,size=(N,n,d))\n",
    "            X=iterated_raw_statistics_GR_234_from_iterated_sample(iterated_data_sample,binom_2,binom_3,binom_4)\n",
    "            pd.DataFrame(X).to_csv(\"Raw_Exponential_iid_234{}.csv\".format((N,n,d)), header=False, index=False)\n",
    "            for choice_scaling in [0,1]:\n",
    "                A=scaled_statistics_GR_234_from_iterated(n,X,binom_2,binom_3,binom_4,choice_scaling)\n",
    "                pd.DataFrame(A).to_csv(\"GR_234_Exponential_iid{}.csv\".format((N,n,d,mean,choice_scaling)), header=False, index=False)\n",
    "    return 'done!'\n",
    "\n",
    "\n",
    "def all_data_inductive234(N):\n",
    "    for n in [16,32,64,128]:\n",
    "        for d in [4,8,16,32,64,128]:\n",
    "            binom_2 = scipy.special.binom(d,2)\n",
    "            binom_3 = scipy.special.binom(d,3)\n",
    "            binom_4 = scipy.special.binom(d,4)\n",
    "            initializing_normal_sample=npr.uniform(0,1,size=(N,n,2))\n",
    "            iterated_data_sample = inductive_model_iterated_numba(initializing_normal_sample,N,n,d)\n",
    "            X=iterated_raw_statistics_GR_234_from_iterated_sample(iterated_data_sample,binom_2,binom_3,binom_4)\n",
    "            pd.DataFrame(X).to_csv(\"Raw_inductive_234{}.csv\".format((N,n,d)), header=False, index=False)\n",
    "            for choice_scaling in [0,1]:\n",
    "                A=scaled_statistics_GR_234_from_iterated(n,X,binom_2,binom_3,binom_4,choice_scaling)\n",
    "                pd.DataFrame(A).to_csv(\"GR_234_inductive{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "    return 'done!'\n",
    "\n",
    "\n",
    "def all_data_Gaussian_Vector234(N):\n",
    "    for tau in [0.7]:\n",
    "        for n in [16,32]:\n",
    "            for d in [256]:\n",
    "                binom_2 = scipy.special.binom(d,2)\n",
    "                binom_3 = scipy.special.binom(d,3)\n",
    "                binom_4 = scipy.special.binom(d,4)\n",
    "                iterated_data_sample = iterated_gaussian_vector_sample(N,n,d,tau)\n",
    "                X=iterated_raw_statistics_GR_234_from_iterated_sample(iterated_data_sample,binom_2,binom_3,binom_4)\n",
    "                pd.DataFrame(X).to_csv(\"Raw_Gaussian_Vector_234{}.csv\".format((N,n,d,tau)), header=False, index=False)\n",
    "                for choice_scaling in [0,1]:\n",
    "                    A=scaled_statistics_GR_234_from_iterated(n,X,binom_2,binom_3,binom_4,choice_scaling)\n",
    "                    pd.DataFrame(A).to_csv(\"GR_234_Gaussian_vector{}.csv\".format((N,n,d,tau,choice_scaling)), header=False, index=False)\n",
    "    return 'done!'\n",
    "\n",
    "\n",
    "def all_data_Geisser_Mantel234(N):\n",
    "    for n in [16]:\n",
    "        for d in [4]:\n",
    "            p = max(math.floor(math.sqrt(2*d)),3)\n",
    "            q=int(p*(p-1)/2)\n",
    "            m = math.floor(p/2)\n",
    "            G = npr.multivariate_normal(np.zeros(p),np.eye(p),size=p+m)\n",
    "            G_N = npr.multivariate_normal(np.zeros(p),np.eye(p),size=(int(N),int(n),int(p+m)))\n",
    "            binom_2 = scipy.special.binom(d,2)\n",
    "            binom_3 = scipy.special.binom(d,3)\n",
    "            binom_4 = scipy.special.binom(d,4)\n",
    "            iterated_data_sample=Geisser_Mantel_iterated_numba(G_N,N,n,p,m)\n",
    "            X=iterated_raw_statistics_GR_234_from_iterated_sample(iterated_data_sample,binom_2,binom_3,binom_4)\n",
    "            pd.DataFrame(X).to_csv(\"Raw_Geisser_Mantel_234{}.csv\".format((N,n,q)), header=False, index=False)\n",
    "            for choice_scaling in [0,1]:\n",
    "                A=scaled_statistics_GR_234_from_iterated(n,X,binom_2,binom_3,binom_4,choice_scaling)\n",
    "                pd.DataFrame(A).to_csv(\"GR_234_Geisser_Mantel{}.csv\".format((N,n,q,choice_scaling)), header=False, index=False)\n",
    "    return 'done!'\n",
    "\n",
    "def all_data_Romano_Siegel234(N):\n",
    "    for n in [16]:\n",
    "        for d in [4]:\n",
    "            p=int(max(math.floor(d/3),1))\n",
    "            q=int(3*p)\n",
    "            g = npr.normal(0,1,size=(N,n,q))\n",
    "            iterated_data_sample=Trunc_d_Romano_Siegel_Numba_iterated_data(g,N,n,p)\n",
    "            binom_2 = scipy.special.binom(d,2)\n",
    "            binom_3 = scipy.special.binom(d,3)\n",
    "            binom_4 = scipy.special.binom(d,4)\n",
    "            X=iterated_raw_statistics_GR_234_from_iterated_sample(iterated_data_sample,binom_2,binom_3,binom_4)\n",
    "            pd.DataFrame(X).to_csv(\"Raw_Trunc_d_Romano_Siegel_234{}.csv\".format((N,n,q)), header=False, index=False)\n",
    "            for choice_scaling in [0,1]:\n",
    "                A=scaled_statistics_GR_234_from_iterated(n,X,binom_2,binom_3,binom_4,choice_scaling)\n",
    "                pd.DataFrame(A).to_csv(\"GR_234_Trunc_d_Romano_Siegel{}.csv\".format((N,n,q,choice_scaling)), header=False, index=False)\n",
    "    return 'done!'\n",
    "\n",
    "############################################################### Section 4: Global variables\n",
    "\n",
    "#start = time.time()\n",
    "\n",
    "N = 500 # Number of iterations\n",
    "n = 16\n",
    "d = 4\n",
    "\n",
    "#choice_scaling = 0 # 1 is finite variance, 0 is for asymptotic/theoretical scaling\n",
    "\n",
    "\n",
    "### Pre-computations of the binomial coefficients \n",
    "binom_2 = scipy.special.binom(d,2)\n",
    "binom_3 = scipy.special.binom(d,3)\n",
    "binom_4 = scipy.special.binom(d,4)\n",
    "\n",
    "### Pre-computations of the normalizing sequences\n",
    "#variance_2 = ((n-2)*(n-2)*(n-1)*(8*n+1))/(32400*n*n*(n+1)*(n+1))\n",
    "#scaling_finite_2 = 1/math.sqrt(variance_2*binom_2)\n",
    "#scaling_2 = 90/math.sqrt(2*binom_2)\n",
    "#variance_3 = (n-2)*(n-1)*(16*n - 96 + 359/n - 269/n**2 - 963/n**3 - 370/n**4)/(5832000*(n+1)**3) \n",
    "#scaling_finite_3 = 1/math.sqrt(variance_3*binom_3)\n",
    "#scaling_3 = 90*math.sqrt(90)/math.sqrt(2*binom_3)\n",
    "#scaling_4 = (90**2)/math.sqrt(2*binom_4)\n",
    "#scaling_finite_4 = scaling_4\n",
    "\n",
    "mean = 1\n",
    "\n",
    "### Pre-sampling the intput data for Geisser-Mantel Numba Model\n",
    "#p = max(math.floor(math.sqrt(2*d)),3)\n",
    "#m = math.floor(p/2)\n",
    "#G = npr.multivariate_normal(np.zeros(p),np.eye(p),size=p+m)\n",
    "#G_N = npr.multivariate_normal(np.zeros(p),np.eye(p),size=(int(N),int(n),int(p+m)))\n",
    "#G_n = npr.multivariate_normal(np.zeros(p),np.eye(p),size=(n,p+m))\n",
    "\n",
    "### Pre-sampling the intput data for Marshall-Olkin Algorithm\n",
    "#t = 1\n",
    "#V = Stable_distrib_data(N,n,t)\n",
    "                                  \n",
    "                                  \n",
    "### Pre-sampling the intput data for the inductive model\n",
    "#initializing_normal_sample=npr.uniform(0,1,size=(N,n,2))\n",
    "\n",
    "### Parameters for the Gaussian vector model\n",
    "#tau = 0.1\n",
    "#tau = 0.3\n",
    "#tau = 0.7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "############################################################### Section 5: Application\n",
    "\n",
    "#all_data_exponential234(N,mean)\n",
    "#all_data_Gaussian_Vector234_to_delete(N)\n",
    "#all_data_Romano_Siegel234(N)\n",
    "#all_data_Geisser_Mantel234(N)\n",
    "#all_data_Gaussian_Vector234(N)\n",
    "#all_data_inductive234(N)\n",
    "\n",
    "\n",
    "########################### Section 5.1: Generating iterated data samples of size N*n*d\n",
    "                                  \n",
    "#p=int(max(math.floor(d/3),1))\n",
    "#g = npr.normal(0,1,size=(N,n,3*p))\n",
    "#iterated_data_sample = Trunc_d_Romano_Siegel_Numba_iterated_data(g,N,n,p)\n",
    "#iterated_data_sample = npr.normal(size=(N,n,d))\n",
    "iterated_data_sample = npr.exponential(1,size=(N,n,d))\n",
    "#iterated_data_sample = npr.multivariate_normal(np.zeros(d),random_cov,size=(int(N),int(n),int(d)))\n",
    "#iterated_data_sample = npr.multivariate_normal(np.zeros(d),toeplitz_cov,size=((N),int(n)))\n",
    "#iterated_data_sample = inductive_model_iterated_numba(initializing_normal_sample,N,n,d)\n",
    "#iterated_data_sample = Gumbel_Marshall_Olkin_iterated_numba(V,d,t)\n",
    "#iterated_data_sample = Geisser_Mantel_iterated_numba(G_N,N,n,p,m)\n",
    "#iterated_data_sample = iterated_gaussian_vector_sample(N,n,d,tau)\n",
    "\n",
    "\n",
    "########################### Section 5.3: Computing the statistics from the iterated data samples\n",
    "\n",
    "X=iterated_raw_statistics_GR_234_from_iterated_sample(iterated_data_sample,binom_2,binom_3,binom_4)\n",
    "#A=scaled_statistics_GR_234_from_iterated(n,X,binom_2,binom_3,binom_4,choice_scaling)\n",
    "                                  \n",
    "########################### Section 5.4: Displaying (histogram) and converting into Panda files the computed statistics\n",
    "\n",
    "#A_df = pd.DataFrame(A)   \n",
    "#A_df.hist()\n",
    "\n",
    "########################### Section 5.5: Storing in Excel files the iterated raw statistics N*2 or N*3 with column (S2,S3,S4)\n",
    "                                  \n",
    "#pd.DataFrame(X).to_csv(\"Raw_Normal_iid{}.csv\".format((N,n,d)), header=False, index=False)\n",
    "#pd.DataFrame(X).to_csv(\"Raw_Inductive{}.csv\".format((N,n,d)), header=False, index=False)\n",
    "#pd.DataFrame(X).to_csv(\"Raw_Random_Cov{}.csv\".format((N,n,d)), header=False, index=False)\n",
    "#pd.DataFrame(X).to_csv(\"Raw_Toeplitz{}.csv\".format((N,n,d)), header=False, index=False)\n",
    "#pd.DataFrame(X).to_csv(\"Raw_Gumbel{}.csv\".format((N,n,d,t)), header=False, index=False)\n",
    "#pd.DataFrame(X).to_csv(\"Raw_Geisser_Mantel{}.csv\".format((N,n,p,m)), header=False, index=False)\n",
    "#pd.DataFrame(X).to_csv(\"Raw_Gaussian_Vector{}.csv\".format((N,n,d,tau)), header=False, index=False)\n",
    "pd.DataFrame(X).to_csv(\"Raw_Exponential_iid{}.csv\".format((N,n,d)), header=False, index=False)\n",
    "#pd.DataFrame(X).to_csv(\"Raw_Romano{}.csv\".format((N,n,d)), header=False, index=False)\n",
    "\n",
    "\n",
    "########################### Section 5.6: Storing in Excel files the final statistics (rescaled raw)\n",
    "                                  \n",
    "#pd.DataFrame(A).to_csv(\"GR_23_inductive{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_23_Gumbel_Marshall_Olkin{}.csv\".format((N,n,d,t,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_23_Geisser_Mantel{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_23_Gaussian_vector{}.csv\".format((N,n,d,tau,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_23_Exponential_iid{}.csv\".format((N,n,d,mean,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_23_Random_Cov_Gauss{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_23_Toeplitz_Cov_Gauss{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_23_Tan{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_23_Trunc_d_Romano_Siegel{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_inductive{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Gumbel_Marshall_Olkin{}.csv\".format((N,n,d,t,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Geisser_Mantel{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Gaussian_vector{}.csv\".format((N,n,d,tau,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Exponential_iid{}.csv\".format((N,n,d,mean,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Random_Cov_Gauss{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Toeplitz_Cov_Gauss{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Tan{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "#pd.DataFrame(A).to_csv(\"GR_234_Trunc_d_Romano_Siegel{}.csv\".format((N,n,d,choice_scaling)), header=False, index=False)\n",
    "\n",
    "\n",
    "#end = time.time()\n",
    "#print(\"Time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.036, 0.068, 0.052, 0.046, 0.04 , 0.07 , 0.028],\n",
       "       [0.166, 0.234, 0.264, 0.294, 0.324, 0.338, 0.534],\n",
       "       [0.126, 0.132, 0.15 , 0.2  , 0.242, 0.276, 0.224],\n",
       "       [0.022, 0.048, 0.05 , 0.036, 0.042, 0.054, 0.024],\n",
       "       [0.824, 0.576, 0.398, 0.342, 0.362, 0.336, 0.988],\n",
       "       [0.458, 0.326, 0.222, 0.204, 0.242, 0.244, 0.982],\n",
       "       [0.022, 0.052, 0.036, 0.038, 0.046, 0.068, 0.042],\n",
       "       [1.   , 1.   , 0.848, 0.638, 0.462, 0.372, 1.   ],\n",
       "       [1.   , 0.904, 0.606, 0.416, 0.308, 0.266, 1.   ],\n",
       "       [0.008, 0.036, 0.042, 0.04 , 0.05 , 0.048, 0.034],\n",
       "       [1.   , 1.   , 1.   , 0.992, 0.856, 0.624, 1.   ],\n",
       "       [1.   , 1.   , 0.992, 0.918, 0.668, 0.464, 1.   ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%timeit\n",
    "#%%timeit -n 1 -r 1 # time cost for 1 run with 1 loop\n",
    "\n",
    "############################################################### Packages\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from scipy.stats import levy_stable  \n",
    "from sklearn.covariance import empirical_covariance\n",
    "import matplotlib.pyplot as plt\n",
    "#import random\n",
    "import math \n",
    "import pandas as pd\n",
    "import scipy.special\n",
    "#from scipy.stats import rankdata\n",
    "import numba\n",
    "import timeit\n",
    "import time\n",
    "import warnings\n",
    "import psutil\n",
    "import array_to_latex as a2l\n",
    "\n",
    "\n",
    "#################################################### Miscellenous: time measure and warning filter\n",
    "#%%timeit\n",
    "#%%timeit -n 1 -r 1 # time cost for 1 run with 1 loop\n",
    "warnings.filterwarnings('ignore')\n",
    "npr.seed(0)\n",
    "######################################################### Computing the powers\n",
    "def power(A,x):\n",
    "    B=A[A>x]\n",
    "    return B.size/A.shape[0]\n",
    "######################################################### OLD VERSIONS\n",
    "def power_for_each_columns_23(A):\n",
    "    X=np.empty((1,3))\n",
    "    for i in range(2):\n",
    "        X[0,i]=power(A[:,i],1.645) # 95-percentile of a N(0,1)\n",
    "    X[0,2]=power((1/np.sqrt(2))*(A[:,2]),1.645) \n",
    "    return X\n",
    "def power_for_each_columns_234(A):\n",
    "    X=np.empty((1,5))\n",
    "    for i in range(3):\n",
    "        X[0,i]=power(A[:,i],1.645) # 95-percentile of a N(0,1)\n",
    "    X[0,3]=power((1/np.sqrt(2))*(A[:,3]),1.645) \n",
    "    X[0,4]=power((1/np.sqrt(3))*(A[:,0]+A[:,1]+A[:,2]),1.645) \n",
    "    return X\n",
    "####################################################### NEW VERSION\n",
    "def power_for_each_columns_234_bis(A,choice_scaling):\n",
    "    if choice_scaling == 0:\n",
    "        X=np.empty((1,5))\n",
    "        for i in range(3):\n",
    "            X[0,i]=power(A[:,i],1.645) # 95-percentile of a N(0,1)\n",
    "        X[0,3]=power((1/np.sqrt(2))*(A[:,3]),1.645) \n",
    "        X[0,4]=power((1/np.sqrt(3))*(A[:,4]),1.645)\n",
    "    elif choice_scaling == 1:\n",
    "        X=np.empty((1,3))\n",
    "        for i in range(2):\n",
    "            X[0,i]=power(A[:,i],1.645) # 95-percentile of a N(0,1)\n",
    "        X[0,2]=power((1/np.sqrt(2))*(A[:,0]+A[:,1]),1.645) \n",
    "    return X\n",
    "######################################################### OLD VERSIONS\n",
    "def total_power_Exponential_iid_23(N,mean,choice_scaling):\n",
    "    X=np.empty((4,3,6))\n",
    "    for j in range(3):\n",
    "        for n in [16, 32, 64, 128]:\n",
    "            for d in [4,8,16,32,64,128]:\n",
    "                d2=int(math.log(d)/math.log(2))-2\n",
    "                n2=int(math.log(n)/math.log(2))-4\n",
    "                A=pd.read_csv('GR_23_Exponential_iid{}.csv'.format((N,n,d,mean,choice_scaling)),header=None)\n",
    "                A=pd.DataFrame(A).to_numpy()\n",
    "                X[n2,j,d2]=power_for_each_columns_23(A)[0,j]\n",
    "    A_1=X[0,:,:]\n",
    "    B=X[1,:,:]\n",
    "    C=X[2,:,:]\n",
    "    D=X[3,:,:]\n",
    "    out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "    pd.DataFrame(out).to_csv(\"Tabular_Exponential_iid_23{}.csv\".format((N,mean,choice_scaling)), header=False, index=False)\n",
    "    return out \n",
    "def total_power_Exponential_iid_234_old(N,mean,choice_scaling):\n",
    "    X=np.empty((4,5,6))\n",
    "    gr=1\n",
    "    for j in range(5):\n",
    "        for n in [16, 32, 64, 128]:\n",
    "            for d in [4,8,16,32,64,128]:\n",
    "                d2=int(math.log(d)/math.log(2))-2\n",
    "                n2=int(math.log(n)/math.log(2))-4\n",
    "                A=pd.read_csv('GR_234_Exponential_iid{}.csv'.format((N,n,d,mean,choice_scaling,gr)),header=None)\n",
    "                A=pd.DataFrame(A).to_numpy()\n",
    "                X[n2,j,d2]=power_for_each_columns_234(A)[0,j]\n",
    "    A_1=X[0,:,:]\n",
    "    B=X[1,:,:]\n",
    "    C=X[2,:,:]\n",
    "    D=X[3,:,:]\n",
    "    out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "    pd.DataFrame(out).to_csv(\"Tabular_Exponential_iid_234_old{}.csv\".format((N,mean,choice_scaling,gr)), header=False, index=False)\n",
    "    return out \n",
    "##################################################### NEW VERSIONS\n",
    "def total_power_Exponential_iid_234(N,mean,choice_scaling):\n",
    "    if choice_scaling == 0:\n",
    "        X=np.empty((4,5,7))\n",
    "        for j in range(5):\n",
    "            for n in [16, 32, 64, 128]:\n",
    "                for d in [4,8,16,32,64,128,256]:\n",
    "                    d2=int(math.log(d)/math.log(2))-2\n",
    "                    n2=int(math.log(n)/math.log(2))-4\n",
    "                    A=pd.read_csv('GR_234_Exponential_iid{}.csv'.format((N,n,d,mean,choice_scaling)),header=None)\n",
    "                    A=pd.DataFrame(A).to_numpy()\n",
    "                    X[n2,j,d2]=power_for_each_columns_234_bis(A,choice_scaling)[0,j]\n",
    "        A_1=X[0,:,:]\n",
    "        B=X[1,:,:]\n",
    "        C=X[2,:,:]\n",
    "        D=X[3,:,:]\n",
    "        out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Exponential_iid_234{}.csv\".format((N,mean,choice_scaling)), header=False, index=False)\n",
    "    elif choice_scaling == 1:\n",
    "        X=np.empty((4,3,7))\n",
    "        for j in range(3):\n",
    "            for n in [16, 32, 64, 128]:\n",
    "                for d in [4,8,16,32,64,128,256]:\n",
    "                    d2=int(math.log(d)/math.log(2))-2\n",
    "                    n2=int(math.log(n)/math.log(2))-4\n",
    "                    A=pd.read_csv('GR_234_Exponential_iid{}.csv'.format((N,n,d,mean,choice_scaling)),header=None)\n",
    "                    A=pd.DataFrame(A).to_numpy()\n",
    "                    X[n2,j,d2]=power_for_each_columns_234_bis(A,choice_scaling)[0,j]\n",
    "        A_1=X[0,:,:]\n",
    "        B=X[1,:,:]\n",
    "        C=X[2,:,:]\n",
    "        D=X[3,:,:]\n",
    "        out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Exponential_iid_234{}.csv\".format((N,mean,choice_scaling)), header=False, index=False)\n",
    "    return out\n",
    "\n",
    "\n",
    "def total_power_Gaussian_vector_234(N,tau,choice_scaling):\n",
    "    if choice_scaling == 0:\n",
    "        X=np.empty((4,5,7))\n",
    "        for j in range(5):\n",
    "            for n in [16, 32, 64, 128]:\n",
    "                for d in [4,8,16,32,64,128,256]:\n",
    "                    d2=int(math.log(d)/math.log(2))-2\n",
    "                    n2=int(math.log(n)/math.log(2))-4\n",
    "                    A=pd.read_csv('GR_234_Gaussian_vector{}.csv'.format((N,n,d,tau,choice_scaling)),header=None)\n",
    "                    A=pd.DataFrame(A).to_numpy()\n",
    "                    X[n2,j,d2]=power_for_each_columns_234_bis(A,choice_scaling)[0,j]\n",
    "        A_1=X[0,:,:]\n",
    "        B=X[1,:,:]\n",
    "        C=X[2,:,:]\n",
    "        D=X[3,:,:]\n",
    "        out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Gaussian_Vector_234{}.csv\".format((N,tau,choice_scaling)), header=False, index=False)\n",
    "    elif choice_scaling == 1:\n",
    "        X=np.empty((4,3,7))\n",
    "        for j in range(3):\n",
    "            for n in [16, 32, 64, 128]:\n",
    "                for d in [4,8,16,32,64,128,256]:\n",
    "                    d2=int(math.log(d)/math.log(2))-2\n",
    "                    n2=int(math.log(n)/math.log(2))-4\n",
    "                    A=pd.read_csv('GR_234_Gaussian_vector{}.csv'.format((N,n,d,tau,choice_scaling)),header=None)\n",
    "                    A=pd.DataFrame(A).to_numpy()\n",
    "                    X[n2,j,d2]=power_for_each_columns_234_bis(A,choice_scaling)[0,j]\n",
    "        A_1=X[0,:,:]\n",
    "        B=X[1,:,:]\n",
    "        C=X[2,:,:]\n",
    "        D=X[3,:,:]\n",
    "        out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Gaussian_Vector_234{}.csv\".format((N,tau,choice_scaling)), header=False, index=False)\n",
    "    return out\n",
    "\n",
    "def total_power_inductive_234(N,choice_scaling):\n",
    "    if choice_scaling == 0:\n",
    "        X=np.empty((4,5,7))\n",
    "        for j in range(5):\n",
    "            for n in [16, 32, 64, 128]:\n",
    "                for d in [4,8,16,32,64,128,256]:\n",
    "                    d2=int(math.log(d)/math.log(2))-2\n",
    "                    n2=int(math.log(n)/math.log(2))-4\n",
    "                    A=pd.read_csv('GR_234_inductive{}.csv'.format((N,n,d,choice_scaling)),header=None)\n",
    "                    A=pd.DataFrame(A).to_numpy()\n",
    "                    X[n2,j,d2]=power_for_each_columns_234_bis(A,choice_scaling)[0,j]\n",
    "        A_1=X[0,:,:]\n",
    "        B=X[1,:,:]\n",
    "        C=X[2,:,:]\n",
    "        D=X[3,:,:]\n",
    "        out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Inductive_234{}.csv\".format((N,choice_scaling)), header=False, index=False)\n",
    "    elif choice_scaling == 1:\n",
    "        X=np.empty((4,3,7))\n",
    "        for j in range(3):\n",
    "            for n in [16, 32, 64, 128]:\n",
    "                for d in [4,8,16,32,64,128,256]:\n",
    "                    d2=int(math.log(d)/math.log(2))-2\n",
    "                    n2=int(math.log(n)/math.log(2))-4\n",
    "                    A=pd.read_csv('GR_234_inductive{}.csv'.format((N,n,d,choice_scaling)),header=None)\n",
    "                    A=pd.DataFrame(A).to_numpy()\n",
    "                    X[n2,j,d2]=power_for_each_columns_234_bis(A,choice_scaling)[0,j]\n",
    "        A_1=X[0,:,:]\n",
    "        B=X[1,:,:]\n",
    "        C=X[2,:,:]\n",
    "        D=X[3,:,:]\n",
    "        out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Inductive_234{}.csv\".format((N,choice_scaling)), header=False, index=False)\n",
    "    return out\n",
    "\n",
    "def total_power_Geisser_Mantel_234(N,choice_scaling):\n",
    "    if choice_scaling == 0:\n",
    "        X=np.empty((4,5,7))\n",
    "        for j in range(5):\n",
    "            for n in [16, 32, 64, 128]:\n",
    "                for d in [3,6,10,28,55,120,231]:\n",
    "                    d2=int(math.log(d)/math.log(2))-2\n",
    "                    n2=int(math.log(n)/math.log(2))-4\n",
    "                    A=pd.read_csv('GR_234_Geisser_Mantel{}.csv'.format((N,n,d,choice_scaling)),header=None)\n",
    "                    A=pd.DataFrame(A).to_numpy()\n",
    "                    X[n2,j,d2]=power_for_each_columns_234_bis(A,choice_scaling)[0,j]\n",
    "        A_1=X[0,:,:]\n",
    "        B=X[1,:,:]\n",
    "        C=X[2,:,:]\n",
    "        D=X[3,:,:]\n",
    "        out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Geisser_Mantel_234{}.csv\".format((N,choice_scaling)), header=False, index=False)\n",
    "    elif choice_scaling == 1:\n",
    "        X=np.empty((4,3,7))\n",
    "        for j in range(3):\n",
    "            for n in [16, 32, 64, 128]:\n",
    "                for d in [3,6,10,28,55,120,231]:\n",
    "                    d2=int(math.log(d)/math.log(2))-2\n",
    "                    n2=int(math.log(n)/math.log(2))-4\n",
    "                    A=pd.read_csv('GR_234_Geisser_Mantel{}.csv'.format((N,n,d,choice_scaling)),header=None)\n",
    "                    A=pd.DataFrame(A).to_numpy()\n",
    "                    X[n2,j,d2]=power_for_each_columns_234_bis(A,choice_scaling)[0,j]\n",
    "        A_1=X[0,:,:]\n",
    "        B=X[1,:,:]\n",
    "        C=X[2,:,:]\n",
    "        D=X[3,:,:]\n",
    "        out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Geisser_Mantel_234{}.csv\".format((N,choice_scaling)), header=False, index=False)\n",
    "    return out\n",
    "\n",
    "def total_power_Romano_Siegel_234(N,choice_scaling):\n",
    "    if choice_scaling == 0:\n",
    "        X=np.empty((4,5,7))\n",
    "        for j in range(5):\n",
    "            for n in [16, 32, 64, 128]:\n",
    "                for d in [3,6,15,30,63,126,255]:\n",
    "                    d2=int(math.log(d)/math.log(2))-2\n",
    "                    n2=int(math.log(n)/math.log(2))-4\n",
    "                    A=pd.read_csv('GR_234_Trunc_d_Romano_Siegel{}.csv'.format((N,n,d,choice_scaling)),header=None)\n",
    "                    A=pd.DataFrame(A).to_numpy()\n",
    "                    X[n2,j,d2]=power_for_each_columns_234_bis(A,choice_scaling)[0,j]\n",
    "        A_1=X[0,:,:]\n",
    "        B=X[1,:,:]\n",
    "        C=X[2,:,:]\n",
    "        D=X[3,:,:]\n",
    "        out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Romano_Siegel_234{}.csv\".format((N,choice_scaling)), header=False, index=False)\n",
    "    elif choice_scaling == 1:\n",
    "        X=np.empty((4,3,7))\n",
    "        for j in range(3):\n",
    "            for n in [16, 32, 64, 128]:\n",
    "                for d in [3,6,15,30,63,126,255]:\n",
    "                    d2=int(math.log(d)/math.log(2))-2\n",
    "                    n2=int(math.log(n)/math.log(2))-4\n",
    "                    A=pd.read_csv('GR_234_Trunc_d_Romano_Siegel{}.csv'.format((N,n,d,choice_scaling)),header=None)\n",
    "                    A=pd.DataFrame(A).to_numpy()\n",
    "                    X[n2,j,d2]=power_for_each_columns_234_bis(A,choice_scaling)[0,j]\n",
    "        A_1=X[0,:,:]\n",
    "        B=X[1,:,:]\n",
    "        C=X[2,:,:]\n",
    "        D=X[3,:,:]\n",
    "        out = np.concatenate((np.concatenate((np.concatenate((A_1,B),axis=0),C),axis=0),D),axis=0)\n",
    "        pd.DataFrame(out).to_csv(\"Tabular_Romano_Siegel_234{}.csv\".format((N,choice_scaling)), header=False, index=False)\n",
    "    return out\n",
    "\n",
    "\n",
    "N = 500\n",
    "mean = 1\n",
    "choice_scaling = 1\n",
    "tau1 = 0.1\n",
    "tau2 = 0.3\n",
    "tau3 = 0.7\n",
    "#total_power_Exponential_iid_23(N,mean,choice_scaling)\n",
    "#total_power_Exponential_iid_234_old(N,mean,choice_scaling)\n",
    "total_power_Exponential_iid_234(N,mean,choice_scaling)\n",
    "total_power_Gaussian_vector_234(N,tau1,choice_scaling)\n",
    "total_power_Gaussian_vector_234(N,tau2,choice_scaling)\n",
    "total_power_Gaussian_vector_234(N,tau3,choice_scaling)\n",
    "total_power_inductive_234(N,choice_scaling)\n",
    "total_power_Geisser_Mantel_234(N,choice_scaling)\n",
    "total_power_Romano_Siegel_234(N,choice_scaling)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=npr.randint(5,size=(5,3))\n",
    "print(A)\n",
    "print(building_col_sum_234(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
